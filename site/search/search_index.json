{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Resumo H\u00e1 neste documento, de forma detalhada, toda a composi\u00e7\u00e3o, regras de uso, regras de neg\u00f3cio e ambientes necess\u00e1rios para que a equipe e apoiadores que estejam diretamente envolvidos nas aplica\u00e7\u00f5es do departamento de Data Analytics da GAV Resorts.","title":"Home"},{"location":"#resumo","text":"H\u00e1 neste documento, de forma detalhada, toda a composi\u00e7\u00e3o, regras de uso, regras de neg\u00f3cio e ambientes necess\u00e1rios para que a equipe e apoiadores que estejam diretamente envolvidos nas aplica\u00e7\u00f5es do departamento de Data Analytics da GAV Resorts.","title":"Resumo"},{"location":"API/","text":"Resumo A utiliza\u00e7\u00e3o de APIs no pipeline de dados \u00e9 recorrente. Tendo isto como premissa, foi desenvolvido um modelo de tratamento para APIs de forma que, independente de qual seja utilizada, haver\u00e1 reaproveitamento de c\u00f3digo. Dessa forma h\u00e1 ganhos expressivos de desempenho no c\u00f3digo e na manuten\u00e7\u00e3o do mesmo. Diagrama de Sequ\u00eania Conforme o modelo abaixo, mantem-se o mesmo padr\u00e3o para todas as API\u00b4s consumidas. sequenceDiagram autonumber View_API->>Control_API: kwargs Control_API->>Model_API: getDF Control_API->>Model_API: getParams Control_API->>Model_API: processJSON Control_API->>Model_API: setBD Model_API ->>API_e_DW: get_token Model_API ->>API_e_DW: api_call Model_API ->>API_e_DW: save_BD API_e_DW -->> Model_API: RESPONSE Model_API -->> Control_API: RESPONSE Control_API -->> View_API: RESPONSE Especifica\u00e7\u00f5es Gerais Model_API Etapa respons\u00e1vel pela modelagem dos POST e GET da API. Nessa camada, \u00e9 feito o tratamento das mensagens de erro, a convers\u00e3o dos campos em dataframe e tamb\u00e9m \u00e9 controlado a inser\u00e7\u00e3o do dataframe no banco de dados de destino. def api_call() M\u00e9todo principal da model. Nela \u00e9 definido o endpoint e o campo desejado no qual deseja armazenar o retorno. def api_call(url, field, max_attempts=3): url : endpoint para requisi\u00e7\u00e3o da API field : campo requerido da reposta json max_attempts : hp\u00e1 uma tratativa que limita em 03 vezes a quantidade de tentativas da requisi\u00e7\u00e3o def refresh_token() Respons\u00e1vel por obter um novo token a partir das credenciais fornecidas para autentica\u00e7\u00e3o. def refresh_token(): def save_bd() def save_bd(df, **kwargs): df : dataframe que ser\u00e1 inserido no banco kwargs **: campo requerido da reposta json def batch_insert_data() def batch_insert_data(df, table_name, engine, schema, batch_size=50000): df : dataframe que ser\u00e1 inserido no banco table_name : tabela de destinmo engine : engine \u00e9 a respons\u00e1vel por fazer a conex\u00e3o com o banco de dados destino schema : scheme de destino batch_size=50000 : limita\u00e7\u00e3o de 50 mil linhas para cada itera\u00e7\u00e3o na inser\u00e7\u00e3o no banco de destino Control_API Esta camada faz a intermedia\u00e7\u00e3o entre a view e a model. Aqui s\u00e3o tratados os par\u00e2metros fornecidos na view e direcionados para a model da API trabalhada. Nota A maior parte dos m\u00e9todos definidos aqui carregam apenas uma lista de parametros **kwargs def getParams() def getParams(**kwargs): **kwargs : lista de argumentos para obten\u00e7\u00e3o de IDs Aten\u00e7\u00e3o! Este m\u00e9todo retorna uma lista de IDs que j\u00e1 constam no banco e que s\u00e3o complementos para outro endpoint. def get_DF() def getDF(**kwargs): **kwargs : lista de argumentos para obten\u00e7\u00e3o do dataFrame. def processJSON() def processJSON(**kwargs): **kwargs : lista de argumentos para obten\u00e7ao do campo json para fazer o dump. def setBD() def setBD(**kwargs): **kwargs : lista de argumentos para fazer a persist\u00eancia no banco. View_API As views s\u00e3o as baseadas nos endpoints. Cada endpoint possui uma lista de argumentos e uma tratativa do banco destino. kwargs = { 'Argumentos', } a = requisicao control return a PowerBI Esta trata-se de todo o conjunto de dados que envolvem a aplica\u00e7\u00e3o do PowerBI. Seguindo a documenta\u00e7\u00e3o, apenas as views ser\u00e3o tratadas. Grupos Retorna os Workspaces (Groups) do Power BI. def getGrupos() def getGrupos(): kwargs = { 'endpoint': \"/groups\", 'params': 'nao', } dfGroups = getDF(**kwargs) return dfGroups endpoint : endpoint definido para os grupos do PowerBI params : validador de parametros. Neste n\u00e3o h\u00e1 parametriza\u00e7\u00e3o. def saveGrupos(dfGroups): def saveGrupos(dfGroups): kwargs = { 'df': dfGroups, 'schema' : 'powerbi', 'table_name' : 'grupos', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe inserido no banco schema : schema destino table_name : tabela destino truncate : valida\u00e7\u00e3o para truncar a tabela. No caso de grupos, n\u00e3o \u00e9 feito o truncate def main(): def main(): df = getGrupos() saveGrupos(df) Executa, respectivamente, o carregamento do dataframe e a sua inser\u00e7\u00e3o no banco de destino. Gateways Retorna os Gateways do Power BI def getGateways(): def getGateways(): kwargs = { 'endpoint': \"/gateways\", 'params': 'nao', } df = getDF(**kwargs) return df endpoint : endpoint definido para os gateways do PowerBI params : validador de parametros. Neste n\u00e3o h\u00e1 parametriza\u00e7\u00e3o. def saveGateways(): def saveGateways(df): kwargs = { 'df': df, 'schema' : 'powerbi', 'table_name' : 'gateways', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe inserido no banco schema : schema destino table_name : tabela destino truncate : valida\u00e7\u00e3o para truncar a tabela. No caso de gateways, n\u00e3o \u00e9 feito o truncate def jsonGateways(): def jsonGateways(df): kwargs = { 'df': df, 'jsonColumn': 'publicKey' } df = processJSON(**kwargs) kwargs = { 'df': df, 'jsonColumn': 'gatewayAnnotation' } df = processJSON(**kwargs) return df df : dataframe inserido no banco jsonColumn : coluna json na qual ser\u00e1 feito o dump def main(): def main(): df = getGateways() df = jsonGateways(df) saveGateways(df) df = getGateways() : obtem o dataframe principal df = jsonGateways(df) : trata os campos json saveGateways(df) : insere o dataframe no banco destino DataSources Retorna as Fontes de Dados no Relat\u00f3rio do Workspace (Group) Aten\u00e7\u00e3o! Depend\u00eancias: PowerBI Grupos e PowerBI Reports def paramsDatasource(): def paramsDatasource(): kwargs = { 'dbname': 'dbname', 'user': 'user', 'password' : 'password', 'host' : 'host', 'port': 'port', 'query':'SELECT g.id AS grupoID, r.datasetId AS reportID FROM powerbi.grupos g JOIN powerbi.reports r ON g.id = r.datasetworkspaceid' } IDs = getParams(**kwargs) return IDs dbname : nome do banco destino user : usu\u00e1rio para autentica\u00e7\u00e3o no banco para consulta password : senha do usu\u00e1rio do banco host : endere\u00e7o do banco port : porta utilizada para conex\u00e3o query : consulta que retorna os valores que se tornar\u00e3o os parametros da requisi\u00e7\u00e3o def getEndPoints(): def getEndPoints(IDs): lista = [] for id in IDs: endpoint = f\"/groups/{id[0]}/datasets/{id[1]}/datasources\" print('item adicionado') print(endpoint) lista.append(endpoint) return lista lista = [] : nome do banco destino for id in IDs: : itera por todos os IDs carregados no m\u00e9todo paramsDatasource() endpoint = f\"/groups/{id[0]}/datasets/{id[1]}/datasources\" : cria uma string com os valores de id[0] e id[1] def getDFDatasources(): def getDFDatasources(IDs): lista = getEndPoints(IDs) kwargs = { 'endpoint': lista, 'params': 'sim', 'IDs': IDs } df = getDF(**kwargs) return df endpoint : passa uma lista de endpoints params : valida se h\u00e1 parametriza\u00e7\u00e3o. Nesta view, h\u00e1 par\u00e2metros IDs : os IDs s\u00e3o os par\u00e2metros passados na requisi\u00e7\u00e3o def jsonDatasources(): def jsonDatasources(df): kwargs = { 'df': df, 'jsonColumn': 'connectionDetails' } df = processJSON(**kwargs) return df df : dataframe com os campos json jsonColumn : coluna json def saveDatasources(): def saveDatasources(df): kwargs = { 'df': df, 'schema' : 'powerbi', 'table_name' : 'datasource', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe a ser salvo schema : esquema de destino table_name : tabela de desteino truncate : valida\u00e7\u00e3o para truncar a tabela de destino antes do insert def main(): def main(): IDs = paramsDatasource() df = getDFDatasources(IDs) df = jsonDatasources(df) saveDatasources(df) IDs = paramsDatasource() : carregando os IDs para parametros das requisi\u00e7\u00f5es df = getDFDatasources(IDs) : carregando dataframe df = jsonDatasources(df) : processando colunas json saveDatasources(df) : inserindo dataframe no banco destino","title":"API"},{"location":"API/#resumo","text":"A utiliza\u00e7\u00e3o de APIs no pipeline de dados \u00e9 recorrente. Tendo isto como premissa, foi desenvolvido um modelo de tratamento para APIs de forma que, independente de qual seja utilizada, haver\u00e1 reaproveitamento de c\u00f3digo. Dessa forma h\u00e1 ganhos expressivos de desempenho no c\u00f3digo e na manuten\u00e7\u00e3o do mesmo.","title":"Resumo"},{"location":"API/#diagrama-de-sequenia","text":"Conforme o modelo abaixo, mantem-se o mesmo padr\u00e3o para todas as API\u00b4s consumidas. sequenceDiagram autonumber View_API->>Control_API: kwargs Control_API->>Model_API: getDF Control_API->>Model_API: getParams Control_API->>Model_API: processJSON Control_API->>Model_API: setBD Model_API ->>API_e_DW: get_token Model_API ->>API_e_DW: api_call Model_API ->>API_e_DW: save_BD API_e_DW -->> Model_API: RESPONSE Model_API -->> Control_API: RESPONSE Control_API -->> View_API: RESPONSE","title":"Diagrama de Sequ\u00eania"},{"location":"API/#especificacoes-gerais","text":"","title":"Especifica\u00e7\u00f5es Gerais"},{"location":"API/#model_api","text":"Etapa respons\u00e1vel pela modelagem dos POST e GET da API. Nessa camada, \u00e9 feito o tratamento das mensagens de erro, a convers\u00e3o dos campos em dataframe e tamb\u00e9m \u00e9 controlado a inser\u00e7\u00e3o do dataframe no banco de dados de destino.","title":"Model_API"},{"location":"API/#def-api_call","text":"M\u00e9todo principal da model. Nela \u00e9 definido o endpoint e o campo desejado no qual deseja armazenar o retorno. def api_call(url, field, max_attempts=3): url : endpoint para requisi\u00e7\u00e3o da API field : campo requerido da reposta json max_attempts : hp\u00e1 uma tratativa que limita em 03 vezes a quantidade de tentativas da requisi\u00e7\u00e3o","title":"def api_call()"},{"location":"API/#def-refresh_token","text":"Respons\u00e1vel por obter um novo token a partir das credenciais fornecidas para autentica\u00e7\u00e3o. def refresh_token():","title":"def refresh_token()"},{"location":"API/#def-save_bd","text":"def save_bd(df, **kwargs): df : dataframe que ser\u00e1 inserido no banco kwargs **: campo requerido da reposta json","title":"def save_bd()"},{"location":"API/#def-batch_insert_data","text":"def batch_insert_data(df, table_name, engine, schema, batch_size=50000): df : dataframe que ser\u00e1 inserido no banco table_name : tabela de destinmo engine : engine \u00e9 a respons\u00e1vel por fazer a conex\u00e3o com o banco de dados destino schema : scheme de destino batch_size=50000 : limita\u00e7\u00e3o de 50 mil linhas para cada itera\u00e7\u00e3o na inser\u00e7\u00e3o no banco de destino","title":"def batch_insert_data()"},{"location":"API/#control_api","text":"Esta camada faz a intermedia\u00e7\u00e3o entre a view e a model. Aqui s\u00e3o tratados os par\u00e2metros fornecidos na view e direcionados para a model da API trabalhada. Nota A maior parte dos m\u00e9todos definidos aqui carregam apenas uma lista de parametros **kwargs","title":"Control_API"},{"location":"API/#def-getparams","text":"def getParams(**kwargs): **kwargs : lista de argumentos para obten\u00e7\u00e3o de IDs Aten\u00e7\u00e3o! Este m\u00e9todo retorna uma lista de IDs que j\u00e1 constam no banco e que s\u00e3o complementos para outro endpoint.","title":"def getParams()"},{"location":"API/#def-get_df","text":"def getDF(**kwargs): **kwargs : lista de argumentos para obten\u00e7\u00e3o do dataFrame.","title":"def get_DF()"},{"location":"API/#def-processjson","text":"def processJSON(**kwargs): **kwargs : lista de argumentos para obten\u00e7ao do campo json para fazer o dump.","title":"def processJSON()"},{"location":"API/#def-setbd","text":"def setBD(**kwargs): **kwargs : lista de argumentos para fazer a persist\u00eancia no banco.","title":"def setBD()"},{"location":"API/#view_api","text":"As views s\u00e3o as baseadas nos endpoints. Cada endpoint possui uma lista de argumentos e uma tratativa do banco destino. kwargs = { 'Argumentos', } a = requisicao control return a","title":"View_API"},{"location":"API/#powerbi","text":"Esta trata-se de todo o conjunto de dados que envolvem a aplica\u00e7\u00e3o do PowerBI. Seguindo a documenta\u00e7\u00e3o, apenas as views ser\u00e3o tratadas.","title":"PowerBI"},{"location":"API/#grupos","text":"Retorna os Workspaces (Groups) do Power BI.","title":"Grupos"},{"location":"API/#def-getgrupos","text":"def getGrupos(): kwargs = { 'endpoint': \"/groups\", 'params': 'nao', } dfGroups = getDF(**kwargs) return dfGroups endpoint : endpoint definido para os grupos do PowerBI params : validador de parametros. Neste n\u00e3o h\u00e1 parametriza\u00e7\u00e3o.","title":"def getGrupos()"},{"location":"API/#def-savegruposdfgroups","text":"def saveGrupos(dfGroups): kwargs = { 'df': dfGroups, 'schema' : 'powerbi', 'table_name' : 'grupos', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe inserido no banco schema : schema destino table_name : tabela destino truncate : valida\u00e7\u00e3o para truncar a tabela. No caso de grupos, n\u00e3o \u00e9 feito o truncate","title":"def saveGrupos(dfGroups):"},{"location":"API/#def-main","text":"def main(): df = getGrupos() saveGrupos(df) Executa, respectivamente, o carregamento do dataframe e a sua inser\u00e7\u00e3o no banco de destino.","title":"def main():"},{"location":"API/#gateways","text":"Retorna os Gateways do Power BI","title":"Gateways"},{"location":"API/#def-getgateways","text":"def getGateways(): kwargs = { 'endpoint': \"/gateways\", 'params': 'nao', } df = getDF(**kwargs) return df endpoint : endpoint definido para os gateways do PowerBI params : validador de parametros. Neste n\u00e3o h\u00e1 parametriza\u00e7\u00e3o.","title":"def getGateways():"},{"location":"API/#def-savegateways","text":"def saveGateways(df): kwargs = { 'df': df, 'schema' : 'powerbi', 'table_name' : 'gateways', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe inserido no banco schema : schema destino table_name : tabela destino truncate : valida\u00e7\u00e3o para truncar a tabela. No caso de gateways, n\u00e3o \u00e9 feito o truncate","title":"def saveGateways():"},{"location":"API/#def-jsongateways","text":"def jsonGateways(df): kwargs = { 'df': df, 'jsonColumn': 'publicKey' } df = processJSON(**kwargs) kwargs = { 'df': df, 'jsonColumn': 'gatewayAnnotation' } df = processJSON(**kwargs) return df df : dataframe inserido no banco jsonColumn : coluna json na qual ser\u00e1 feito o dump","title":"def jsonGateways():"},{"location":"API/#def-main_1","text":"def main(): df = getGateways() df = jsonGateways(df) saveGateways(df) df = getGateways() : obtem o dataframe principal df = jsonGateways(df) : trata os campos json saveGateways(df) : insere o dataframe no banco destino","title":"def main():"},{"location":"API/#datasources","text":"Retorna as Fontes de Dados no Relat\u00f3rio do Workspace (Group) Aten\u00e7\u00e3o! Depend\u00eancias: PowerBI Grupos e PowerBI Reports","title":"DataSources"},{"location":"API/#def-paramsdatasource","text":"def paramsDatasource(): kwargs = { 'dbname': 'dbname', 'user': 'user', 'password' : 'password', 'host' : 'host', 'port': 'port', 'query':'SELECT g.id AS grupoID, r.datasetId AS reportID FROM powerbi.grupos g JOIN powerbi.reports r ON g.id = r.datasetworkspaceid' } IDs = getParams(**kwargs) return IDs dbname : nome do banco destino user : usu\u00e1rio para autentica\u00e7\u00e3o no banco para consulta password : senha do usu\u00e1rio do banco host : endere\u00e7o do banco port : porta utilizada para conex\u00e3o query : consulta que retorna os valores que se tornar\u00e3o os parametros da requisi\u00e7\u00e3o","title":"def paramsDatasource():"},{"location":"API/#def-getendpoints","text":"def getEndPoints(IDs): lista = [] for id in IDs: endpoint = f\"/groups/{id[0]}/datasets/{id[1]}/datasources\" print('item adicionado') print(endpoint) lista.append(endpoint) return lista lista = [] : nome do banco destino for id in IDs: : itera por todos os IDs carregados no m\u00e9todo paramsDatasource() endpoint = f\"/groups/{id[0]}/datasets/{id[1]}/datasources\" : cria uma string com os valores de id[0] e id[1]","title":"def getEndPoints():"},{"location":"API/#def-getdfdatasources","text":"def getDFDatasources(IDs): lista = getEndPoints(IDs) kwargs = { 'endpoint': lista, 'params': 'sim', 'IDs': IDs } df = getDF(**kwargs) return df endpoint : passa uma lista de endpoints params : valida se h\u00e1 parametriza\u00e7\u00e3o. Nesta view, h\u00e1 par\u00e2metros IDs : os IDs s\u00e3o os par\u00e2metros passados na requisi\u00e7\u00e3o","title":"def getDFDatasources():"},{"location":"API/#def-jsondatasources","text":"def jsonDatasources(df): kwargs = { 'df': df, 'jsonColumn': 'connectionDetails' } df = processJSON(**kwargs) return df df : dataframe com os campos json jsonColumn : coluna json","title":"def jsonDatasources():"},{"location":"API/#def-savedatasources","text":"def saveDatasources(df): kwargs = { 'df': df, 'schema' : 'powerbi', 'table_name' : 'datasource', 'truncate' : 'yes' } setBD(**kwargs) df : dataframe a ser salvo schema : esquema de destino table_name : tabela de desteino truncate : valida\u00e7\u00e3o para truncar a tabela de destino antes do insert","title":"def saveDatasources():"},{"location":"API/#def-main_2","text":"def main(): IDs = paramsDatasource() df = getDFDatasources(IDs) df = jsonDatasources(df) saveDatasources(df) IDs = paramsDatasource() : carregando os IDs para parametros das requisi\u00e7\u00f5es df = getDFDatasources(IDs) : carregando dataframe df = jsonDatasources(df) : processando colunas json saveDatasources(df) : inserindo dataframe no banco destino","title":"def main():"},{"location":"Leitura_Notas_Fiscais/","text":"Nota F\u00e1cil O que \u00e9? Trata-se de um algoritmo desenvolvido em Python, meticulosamente estruturado para processar arquivos de notas fiscais em formato PDF. O seu prop\u00f3sito \u00e9 extrair as informa\u00e7\u00f5es cruciais desses documentos, tais como n\u00famero da nota, valor l\u00edquido, data de emiss\u00e3o, CNPJ e Raz\u00e3o Social tanto do prestador quanto do tomador de servi\u00e7o. O resultado desse processo \u00e9 ent\u00e3o exportado e organizado em uma planilha do Excel, proporcionando um compilado abrangente e organizado das notas fiscais processadas. Ambiente Para garantir o funcionamento adequado do algoritmo, \u00e9 recomend\u00e1vel utilizar o Python fornecido pelo Anaconda. Al\u00e9m disso, \u00e9 necess\u00e1rio configurar a instala\u00e7\u00e3o de dois pacotes essenciais: Tesseract e Poopler para a leitura de imagens, conforme explicado detalhadamente no t\u00f3pico 2.0. Essa configura\u00e7\u00e3o \u00e9 crucial para garantir a efici\u00eancia e precis\u00e3o do algoritmo, permitindo uma leitura eficaz das notas fiscais em formato PDF. Estrutra do algortimo O algoritmo \u00e9 composto por 6 arquivos em Python, de forma modularizada: leitura_NF.py modulos_vairaveis.py modulos_prefeituras.py modulos_renomeia.py modulos_empresas.py modulos_ler_imagem.py 1.0 Arquivo \"leitura_NF.py\" Esse \u00e9 o algoritmo que ser\u00e1 executado para o processo de leitura rodar. Primeiramente, preparo ambiente para a exporta\u00e7\u00e3o dos dados das notas. Assim, crio um DataFrame para alocar todas as vari\u00e1veis escolhidas das notas, e algumas colunas de metadados. df = pd.DataFrame(columns=['Numero NF', 'Data Emissao', 'Valor Bruto', 'CNPJ Prestador', 'CNPJ Tomador', 'Razao Social Prestador','Razao Social Tomador', 'Prefeitura', 'Script','Caminho', 'Caminho Curto', 'Arquivo']) Numero NF : n\u00famero da nota fiscal Data Emissao : data (ou data e hora) em que a nota foi emitida Valor Bruto : valor bruto da nota fiscal (sem descontos) CNPJ Prestador : n\u00famero do CNPJ do colaborador CNPJ Tomadorr : n\u00famero do CNPJ da empresa GAV Razao Social Prestador : raz\u00e3o social do colaborador Razao Social Tomador : raz\u00e3o social da empresa GAV Prefeitura : local de presta\u00e7\u00e3o do servi\u00e7o (ou prefeitura da nota emitida) Script : nome da fun\u00e7\u00e3o no c\u00f3digo que a nota foi executada Caminho : caminho original de onde vem a nota Caminho Curto : \u00faltimas 3 pastas do caminho original Arquivo : nome do arquivo 1.1 Entrada e sa\u00edda de dados H\u00e1 duas forma de definir o input e output dos arquivos nesse c\u00f3digo: Em formato de vari\u00e1vel, importando as vari\u00e1veis de caminho de entrada e sa\u00edda de um arquivo .env. Assim, tamb\u00e9m crio uma lista com os diret\u00f3rios de input. d1 = os.getenv('CAMINHO_NF') d2 = os.getenv('CAMINHO_NF_TLK') tabela_resposta = os.getenv('CAMINHO_RESULTADO') lista_diretorios = [d1,d2] os.getenv : recupera a vari\u00e1vel do arquivo env tabela_resposta : cont\u00e9m o caminho de exporta\u00e7\u00e3o do dataframe produzido no c\u00f3digo lista_diretorios : lista que guarda os caminhos das notas Definindo no pr\u00f3prio c\u00f3digo diretamente d1 = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Notas-Salas' d2 = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Notas-Promo-Tlmk' tabela_resposta = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Resultado\\Leitura.xlsx' lista_diretorios = [d1,d2] A diferen\u00e7a \u00e9 que a primeira torna o c\u00f3digo mais limpo e organizado. 1.2 Contagem de arquivos Ap\u00f3s estabelecer os diret\u00f3rios, navego por cada pasta e contabilizo a quantidade total de arquivos presentes. Isso \u00e9 feito com o prop\u00f3sito de criar um monitoramento que apresenta a porcentagem de notas lidas em rela\u00e7\u00e3o ao total previamente definido. Esse acompanhamento visa proporcionar uma vis\u00e3o clara do progresso na leitura das notas em rela\u00e7\u00e3o \u00e0 meta estabelecida. qtd_arquivos = 0 for i in lista_diretorios: for diretorio_atual, subdiretorios, arquivos in os.walk(lista_diretorios[lista_diretorios.index(i)]): for arquivo in arquivos: qtd_arquivos += 1 1.3 Cria\u00e7\u00e3o do Loop Estabele\u00e7o um loop que percorre cada diret\u00f3rio da lista de diret\u00f3rios, adentrando em cada pasta de cada diret\u00f3rio e examinando, posteriormente, cada arquivo contido em cada pasta. Durante esse processo, verifica-se se o arquivo possui a extens\u00e3o .pdf. Caso positivo, s\u00e3o definidas duas vari\u00e1veis essenciais: o caminho completo do arquivo (caminho) e o caminho relativo em rela\u00e7\u00e3o ao diret\u00f3rio principal (caminho curto). Por fim, o script imprime o caminho completo do arquivo em quest\u00e3o. posicao = 0 for item in lista_diretorios: diretorio_inicial = lista_diretorios[posicao] posicao += 1 for diretorio_atual, subdiretorios, arquivos in os.walk(diretorio_inicial): for arquivo in arquivos: try: if arquivo.lower().endswith('.pdf'): # Se \u00e9 da extens\u00e3o .pdf caminho = diretorio_atual + '\\\\' + arquivo caminho_curto = caminho.split('\\\\')[-4:-1] caminho_curto = (caminho_curto[0] + '/' + caminho_curto[1] + '/' + caminho_curto[2]) print('CAMINHO DA NOTA =', caminho) caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho 1.4 Leitura da Nota Ap\u00f3s essa etapa, invoco a fun\u00e7\u00e3o respons\u00e1vel pela leitura da nota \"le_contrato\" (esclarecida no t\u00f3pico 3.0), armazenando o resultado na vari\u00e1vel \"texto\". Em seguida, o conte\u00fado passa por um processo de limpeza de espa\u00e7amentos e \u00e9 armazenado na vari\u00e1vel \"texto_lista\". Posteriormente, s\u00e3o removidos os valores vazios, transformando a vari\u00e1vel em \"texto_limpo\". Dessa forma, temos agora a vari\u00e1vel fundamental para todo o c\u00f3digo, que cont\u00e9m o texto totalmente tratado e pronto para ser utilizado nas pr\u00f3ximas etapas. # Executa fun\u00e7\u00e3o de ler o pdf modulos_variaveis_v13.le_contrato(caminho) # Armazena o texto texto = modulos_variaveis_v13.output_string.getvalue() # Tira os espa\u00e7amentos texto_lista = texto.split('\\n') caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho 1.5 Direcionamento de prefeitura Ap\u00f3s a extra\u00e7\u00e3o do texto da nota, a vari\u00e1vel \"texto_limpo\" \u00e9 submetida a v\u00e1rias condicionais com o objetivo de determinar a qual prefeitura ela se relaciona. Uma vez identificada a prefeitura espec\u00edfica, o script executa o processo de captura das vari\u00e1veis pertinentes utilizando o \"modulo_variaveis\", cujo funcionamento ser\u00e1 detalhado posteriormente. Esse conjunto de condicionais visa direcionar o fluxo do programa para a execu\u00e7\u00e3o das etapas espec\u00edficas associadas a cada prefeitura, garantindo uma abordagem personalizada e eficiente para cada caso. # PREFEITURA DE NATAL elif any('Prefeitura Municipal do Natal' in item for item in texto_limpo): modulos_variaveis.script_natal(texto_limpo, caminho, caminho_curto, arquivo, df) # PREFEITURA DE MANAUS elif any('PREFEITURA DE MANAUS' in item for item in texto_limpo): modulos_variaveis.script_manaus(texto_limpo, caminho, caminho_curto, arquivo, df) # PREFEITURA DE RIO BRANCO elif any('Prefeitura do Munic\u00edpio de Rio Branco' in item for item in texto_limpo): modulos_variaveis.script_rio_branco(texto_limpo, caminho, caminho_curto, arquivo, df) modulos_variaveis : m\u00f3dulo que cont\u00e9m o direcionamento de cada prefeitura espec\u00edfica modulos_variaveis.script_natal : fun\u00e7\u00e3o que direciona a execu\u00e7\u00e3o da fun\u00e7\u00e3o espec\u00edfica da prefeitura natal, contida no \"modulo_variaveis\" 1.6 PDF com imagem Ap\u00f3s passar por todas as condicionais de processamento dos textos relacionadas \u00e0s prefeituras, o c\u00f3digo realiza uma verifica\u00e7\u00e3o final. Ele avalia se a vari\u00e1vel \"texto_limpo\" cont\u00e9m os caracteres '\\x0c' ou '\\n0'. Se essa condi\u00e7\u00e3o for satisfeita, indica que o texto \u00e9 proveniente de uma nota em PDF n\u00e3o selecion\u00e1vel, como uma imagem de um print. elif texto == '\\x0c' \\ or '\\x0c' in texto \\ or '\\n0' in texto : Nesse cen\u00e1rio, ao atender a essa condi\u00e7\u00e3o, o c\u00f3digo executa um processo para extrair os dados dessa imagem (explicado no t\u00f3pico \"modulo_ler_imagem\"), e aloca o resultado na vari\u00e1vel \"texto_imagem\". Assim, \"texto imagem\" que recebeu uma lista com o resultado da leitura da nota em imagem, passa por um processo de limpeza, eliminando caracteres vazios e linhas nulas. script = 'imagem' # Executa scritp de leitra de imagem texto_imagem = modulos_ler_imagem.get_text_from_any_pdf(caminho) texto_imagem = texto_imagem.split('\\n') texto_imagem = [item.strip() for item in texto_imagem if item.strip() != ''] caminho : caminho de localiza\u00e7\u00e3o do arquivo A partir deste ponto, o c\u00f3digo continua a percorrer as condi\u00e7\u00f5es subsequentes, verificando se o conte\u00fado se encaixa em alguma prefeitura espec\u00edfica. # PREFEITURA DE UBERABA IMAGEM elif any('PREFEITURA MUNICIPAL DE UBERABA' in item for item in texto_imagem): modulos_variaveis.script_uberaba_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) # PREFEITURA DE BEL\u00c9M IMAGEM elif any('PREFEITURA MUNICIPAL DE BELEM' in item for item in texto_imagem): modulos_variaveis.script_belem_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) # PREFEITURA DE ANANINDEUA IMAGEM elif any('PREFEITURA MUNICIPAL DE ANANINDEUA' in item for item in texto_imagem): modulos_variaveis.script_ananindeua_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) modulos_variaveis : m\u00f3dulo que cont\u00e9m o direcionamento de cada prefeitura espec\u00edfica modulos_variaveis.script_uberaba_imagem : fun\u00e7\u00e3o que direciona a execu\u00e7\u00e3o da fun\u00e7\u00e3o espec\u00edfica da prefeitura de uberaba (em formato de imagem), contida no \"modulo_variaveis\" Nota Por que algumas notas s\u00e3o em formato de PDF normal e outras em formato PDF com imagem? A varia\u00e7\u00e3o no formato das notas em PDF ocorre devido ao processo descentralizado de gera\u00e7\u00e3o, onde cada colaborador \u00e9 respons\u00e1vel pela emiss\u00e3o de suas pr\u00f3prias notas. Durante esse processo, algumas notas s\u00e3o geradas de maneira n\u00e3o padr\u00e3o, resultando em PDFs com texto n\u00e3o selecion\u00e1vel. 1.7 Prefeitura n\u00e3o existente Ap\u00f3s percorrer todas as condi\u00e7\u00f5es relacionadas aos casos de texto e imagem, e n\u00e3o encontrar uma correspond\u00eancia em nenhuma delas, a vari\u00e1vel \u00e9 redirecionada para a cl\u00e1usula \"else\". Nesse ponto, o c\u00f3digo tenta, pelo menos, extrair o nome da prefeitura associada ao novo caso.Se bem-sucedido, o nome da prefeitura \u00e9 extra\u00eddo, e as outras vari\u00e1veis s\u00e3o configuradas como brancas. Em seguida, todas as vari\u00e1veis s\u00e3o adicionadas a uma lista, que \u00e9 inserida no dataframe. No caso de n\u00e3o ser poss\u00edvel extrair o nome da prefeitura, a vari\u00e1vel fica com o valor \"nao_achado\", e, juntamente com as outras vari\u00e1veis em branco, uma lista \u00e9 criada e inserida como uma nova linha no dataframe. Nesse caso, a vari\u00e1vel script, que cont\u00e9m qual script da vari\u00e1vel modulo_variaveis foi ativado, fica com o valor \"sem_codigo\". Essa abordagem permite lidar de maneira flex\u00edvel com situa\u00e7\u00f5es n\u00e3o previamente mapeadas, buscando ao menos identificar o nome da prefeitura mesmo quando a estrutura do documento n\u00e3o segue os padr\u00f5es conhecidos. else: for indice, item in enumerate(texto_imagem): if 'prefeitura' in item.lower() or 'munic\u00edpio' in item.lower(): prefeitura = texto_imagem[indice] break else: prefeitura = 'nao_achado' num_nf = '' data_emissao = '' vlr_liquido = '' cnpj_prestador = '' cnpj_tomador = '' razao_prestador = '' razao_tomador = '' script = 'sem_codigo' lista_variaveis = [num_nf,data_emissao, vlr_liquido, cnpj_prestador, cnpj_tomador, razao_prestador, razao_tomador, prefeitura, script, caminho, caminho_curto, arquivo] # Inser\u00e7\u00e3o da lista no DataFrame df.loc[len(df)] = lista_variaveis df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo 1.8 Tentativa e Erro Todo esse c\u00f3digo que exerce sobre esse arquivo selecionado no loop de pastas, passa por um processo de tentativa e erro, utilizando o \"try except\". Dessa forma, mesmo que ocorra algum erro durante a execu\u00e7\u00e3o, o algoritmo n\u00e3o ir\u00e1 travar. Nesse sentido, ele simplesmente ir\u00e1 entender aquela nota como erro, preencher a lista_variaveis com a palavra \"erro\" nas vari\u00e1veis, e inseri-la nno dataframe. try: if arquivo.lower().endswith('.pdf'): # Se \u00e9 da extens\u00e3o .pdf caminho = diretorio_atual + '\\\\' + arquivo caminho_curto = caminho.split('\\\\')[-4:-1] caminho_curto = (caminho_curto[0] + '/' + caminho_curto[1] + '/' + caminho_curto[2]) print('CAMINHO DA NOTA =', caminho) ... except Exception as e: lista_variaveis = ['erro', 'erro', 'erro', 'erro', 'erro', 'erro', 'erro', 'erro', e, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis 1.9 Carregamento de leitura Para haver um acompanhamento da leitura, o algortimo expoe no terminal algumas informa\u00e7\u00f5es: O nome do arquivo (escrito no no in\u00edcio do loop); Quantidade de notas lidas; Quantidade e porcentagem de notas imperfeitas (qualquer uma que n\u00e3o tiver a palavra \"script\" dentro da vari\u00e1vel \"script\", ou seja, que n\u00e3o tem nenhuma un\u00e7\u00e3o apropriada para aquela prefeitura); Visualiza\u00e7\u00e3o de uma barra de progresso (baseada na quantidade de notas lidas pelo total). # Calcula notas com algum tipo de erro ou n\u00e3o leitura Soma_Notas_Erro = np.sum(np.logical_not(df['Script'].str.contains('script'))) Porcentagem = round((Soma_Notas_Erro / qtd_arquivos) * 100,2) # Mostra barra de processamento print('Quantidade NOTAS LIDAS =', len(df),'/', qtd_arquivos) print('Quantidade NOTAS IMPERFEITAS =', Soma_Notas_Erro, '==', Porcentagem, '%') lista_df = list(range(1,len(df)+1)) for i in tqdm(list(range(1,len(df)+1)), total=qtd_arquivos, unit=\"item\", bar_format=\"{desc}: {percentage:.2f}% {bar}\",desc=\"Processando\"): pass qtd_arquivos : quantidade total de arquivos, calculada na sess\u00e3o \"1.2 Contagem de arquivos\" 1.10 Tratamento e Limpeza do DataFrame Ap\u00f3s a cria\u00e7\u00e3o do DataFrame, realiza-se ajustes para aprimorar a qualidade dos dados. Especificamente: Coluna CNPJ: Remo\u00e7\u00e3o de caracteres n\u00e3o num\u00e9ricos, mantendo apenas os d\u00edgitos. Corre\u00e7\u00e3o de um CNPJ espec\u00edfico para evitar interpreta\u00e7\u00e3o incorreta Coluna Valor: Elimina\u00e7\u00e3o de caracteres n\u00e3o num\u00e9ricos, garantindo apenas valores num\u00e9ricos. Coluna Data: Substitui\u00e7\u00e3o de '-' por '/', uniformizando o formato. Padroniza\u00e7\u00e3o de todas as datas para o formato dd/mm/aaaa. df['CNPJ Prestador'] = df['CNPJ Prestador'].str.replace(r'\\D', '', regex=True) df['CNPJ Prestador'] = df['CNPJ Prestador'].str.strip() df['CNPJ Tomador'] = df['CNPJ Tomador'].str.replace(r'\\D', '', regex=True) df['CNPJ Tomador'] = df['CNPJ Tomador'].str.strip() # Substitui a leitura errada do cnpj de GAV GRAMADO TRES df['CNPJ Tomador'] = df['CNPJ Tomador'].str.replace('90094155000102', '50094155000102') df['Valor Liquido'] = df['Valor Liquido'].str.replace(r'[a-zA-Z$]', '', regex=True) df['Data Emissao'] = df['Data Emissao'].str.replace(r'-', '/', regex=True) df['Data Emissao'] = df['Data Emissao'].str.extract(r'(\\d{2}/\\d{2}/\\d{4})', expand = False) 1.11 Valida\u00e7\u00e3o do CNPJ Para validar a consist\u00eancia dos CNPJs do Tomador nas notas fiscais em rela\u00e7\u00e3o \u00e0s empresas registradas no banco de dados, realizamos a extra\u00e7\u00e3o da tabela de empresas do DW, situada no m\u00f3dulo empresas. Utilizando Python, efetuamos a limpeza e tratamento necess\u00e1rios na tabela de empresas para garantir a integridade dos dados. Em seguida, comparamos os CNPJs do Tomador nas notas fiscais com os CNPJs da tabela de empresas. Quando h\u00e1 correspond\u00eancia, incorporamos ao DataFrame das notas fiscais duas novas colunas: 'Codigo Tomador' com o c\u00f3digo da empresa correspondente, e 'Empresa Tomador' com a raz\u00e3o social correspondente. Este processo tem como objetivo assegurar a conformidade dos CNPJs do Tomador com as empresas registradas, proporcionando uma an\u00e1lise consistente dos dados. # Conex\u00e3o com tabela empresas do banco df_empresas = modulos_empresas.df_empresas df_empresas = df_empresas.drop_duplicates(subset='cnpj', keep='first') df_empresas['cod_empresa'] = df_empresas['cod_empresa'].astype(int) df_empresas['cod_empresa'] = round(df_empresas['cod_empresa']) df_empresas['cod_empresa'] = df_empresas['cod_empresa'].astype(str) # Especifica o codigo da empresa df['Codigo Tomador'] = np.where( df['CNPJ Tomador'].isin(df_empresas['cnpj']), df['CNPJ Tomador'].map(df_empresas.set_index('cnpj')['cod_empresa']), '-' ) # Especifica a razao social da empresa df['Empresa Tomador'] = np.where( df['CNPJ Tomador'].isin(df_empresas['cnpj']), df['CNPJ Tomador'].map(df_empresas.set_index('cnpj')['empresa']), '-' ) 1.12 Coluna de Novos Nomes Com o intuito de padronizar os nomes dos arquivos de acordo com o conte\u00fado das notas fiscais, introduzimos uma coluna com um formato padr\u00e3o: \"Raz\u00e3o social do prestador + c\u00f3digo do tomador + valor do servi\u00e7o da nota\". A cria\u00e7\u00e3o dessa coluna \u00e9 realizada invocando a fun\u00e7\u00e3o coluna_altera_nome do m\u00f3dulo vari\u00e1veis. Posteriormente, efetuamos uma limpeza na coluna, substituindo caracteres espec\u00edficos e removendo acentos utilizando a fun\u00e7\u00e3o unidecode. Essa estrat\u00e9gia visa estabelecer uma identifica\u00e7\u00e3o uniforme e descritiva para cada nota fiscal, facilitando a organiza\u00e7\u00e3o e refer\u00eancia dos arquivos # Cria a coluna com o nome do arquivo alterado df['Arquivo_Nome_Alterado'] = df.apply(modulos_variaveis.coluna_altera_nome, axis=1) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].apply(modulos_variaveis_v13.limpa_acento) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].str.replace(\"'\", '') df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].str.replace(\"@\", '') df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].astype(str) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].apply(unidecode) Depois, \u00e9 chamada a fun\u00e7\u00e3o que renomeia o pr\u00f3prio arquivo, contida no modulo renomear. # Renomeia os arquivos modulos_renomear.renomeia(df) 1.13 Exporta\u00e7\u00e3o do Resultado Durante o tratamento do dataframe j\u00e1 feito, utiliza-se alguns comandos de exporta\u00e7\u00e3o dessa tabela para o Excel, com o intuito de garantir que, mesmo que o c\u00f3digo d\u00ea algum erro no final, seja poss\u00edvel exportar a tabela, mesmo sem tratamento df.to_excel(r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Resultado.xlsx', index=False) Mas no fim do c\u00f3digo, exporta-se o dataframe pelo caminho de retorno indicado no arquivo .env df.to_excel(tabela_resposta, index=False) 1.14 Contagem do Tempo Por fim, \u00e9 exposto no terminal o tempo total da leitura das notas. # Conta o tempo de execu\u00e7\u00e3o tempo_final = time.time() tempo_total = (tempo_final - tempo_inicio)/60 print('exportado para excel') print('Tempo total', tempo_total, 'minutos') 2.0 Arquivo \"modulos_variaveis.py\" O objetivo principal deste m\u00f3dulo \u00e9 orientar a execu\u00e7\u00e3o para fun\u00e7\u00f5es espec\u00edficas dentro do m\u00f3dulo_prefeitura e tamb\u00e9m armazenar algumas fun\u00e7\u00f5es de uso geral que ser\u00e3o utilizadas no m\u00f3dulo principal. 2.1 Fun\u00e7\u00e3o para nota PDF Um exemplo de fun\u00e7\u00e3o de direcionamento para o m\u00f3dulo_prefeitura \u00e9 o seguinte: Inicialmente, \u00e9 determinada uma vari\u00e1vel chamada \"script\" que indica o nome do script atualmente em execu\u00e7\u00e3o. Em seguida, \u00e9 invocada a fun\u00e7\u00e3o \"pref_natal\" do m\u00f3dulo_prefeitura. Esta fun\u00e7\u00e3o \u00e9 respons\u00e1vel por extrair as vari\u00e1veis necess\u00e1rias de uma nota, seguindo o contexto do script atual. As vari\u00e1veis extra\u00eddas s\u00e3o ent\u00e3o reunidas em uma lista. Posteriormente, essa lista de vari\u00e1veis \u00e9 inserida no dataframe que est\u00e1 sendo constru\u00eddo, possibilitando a organiza\u00e7\u00e3o e manipula\u00e7\u00e3o dos dados. Este procedimento fornece uma clareza sobre o fluxo de execu\u00e7\u00e3o do script, garantindo que as vari\u00e1veis relevantes sejam corretamente extra\u00eddas e incorporadas ao dataframe em constru\u00e7\u00e3o. def script_natal(texto_limpo, caminho, caminho_curto, arquivo, df): script = 'natal_script' modulo_prefeitura.pref_natal(texto_limpo) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_limpo : texto extra\u00eddo da leitura do arquivo pdf caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho arquivo : : nome do arquivo df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo lista_variaveis : lista contendo todas as vari\u00e1veis extra\u00eddas da nota Essa fun\u00e7\u00e3o de \"script_prefeituraX\" se repete dezenas de vezes, pois \u00e9 criado a cada prefeitura existente dentro das pastas de notas. 2.2 Fun\u00e7\u00e3o para nota PDF de baixa qualidade Existe uma variante adicional da fun\u00e7\u00e3o \"script\", na qual a nota inicial \u00e9 apresentada como um texto convencional. No entanto, dentro dessa fun\u00e7\u00e3o, \u00e9 realizada uma leitura de imagem da nota para otimizar a qualidade do texto extra\u00eddo. Isso se torna especialmente relevante em casos nos quais algumas prefeituras disponibilizam notas em formato PDF comum, resultando em uma extra\u00e7\u00e3o de texto de baixa qualidade. Ao empregar a leitura de imagem, busca-se aprimorar a precis\u00e3o e clareza do texto obtido. def script_rio_largo(caminho, caminho_curto, arquivo, df): script = 'rio_largo_script' texto_imagem = modulos_ler_imagem_v1.get_text_from_any_pdf(caminho) texto_imagem = texto_imagem.split('\\n') texto_imagem = [item.strip() for item in texto_imagem if item.strip() != ''] modulos_prefeitura.pref_rio_largo(texto_imagem) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_imagem : texto extra\u00eddo da leitura do arquivo pdf com imagem 2.3 Fun\u00e7\u00e3o para nota PDF de imagem Existe tamb\u00e9m uma tereceira variante adicional da fun\u00e7\u00e3o \"script\", usada nas notas pdf com imagem. Com isso, em vez da entrada de texto_limpo, ter\u00e1 de texto_imagem. Neste contexto, dado que a fun\u00e7\u00e3o principal do algoritmo j\u00e1 incorpora a capacidade de realizar a leitura de imagens ao identificar que um PDF \u00e9 do tipo imagem, n\u00e3o \u00e9 necess\u00e1rio explicitar a fun\u00e7\u00e3o de leitura de imagem dentro da fun\u00e7\u00e3o \"script\". Em vez disso, basta utilizar o nome da vari\u00e1vel que cont\u00e9m a imagem como entrada para garantir a efetiva leitura e processamento. def script_recife(texto_imagem, caminho, caminho_curto, arquivo, df): script = 'recife_script' modulos_prefeitura.pref_recife(texto_imagem) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_imagem : texto extra\u00eddo da leitura do arquivo pdf com imagem 2.4 Fun\u00e7\u00e3o para leitura da nota A fun\u00e7\u00e3o le_contrato tem como objetivo ler um contrato em formato PDF, utilizando a biblioteca PDFminer Ela realiza a extra\u00e7\u00e3o de texto de cada p\u00e1gina do PDF e armazena o resultado em uma vari\u00e1vel global chamada output_string. Essa fun\u00e7\u00e3o \u00e9 \u00fatil quando se deseja processar o conte\u00fado textual de contratos presentes em documentos PDF. def le_contrato(caminho): '''L\u00ea contrato em pdf''' # Vari\u00e1vel global para armazenar o texto extra\u00eddo global output_string output_string = StringIO() # Abre o arquivo PDF no modo de leitura bin\u00e1ria with open(caminho, 'rb') as in_file: # Cria um objeto PDFParser para analisar o conte\u00fado do arquivo PDF parser = PDFParser(in_file) # Gera um objeto PDFDocument com base no parser doc = PDFDocument(parser) # Cria\u00e7\u00e3o de objetos para gerenciar recursos e converter texto rsrcmgr = PDFResourceManager() # TextConverter converte o conte\u00fado do PDF em texto device = TextConverter(rsrcmgr, output_string, laparams=LAParams()) # Cria um objeto PDFPageInterpreter para interpretar as p\u00e1ginas do PDF interpreter = PDFPageInterpreter(rsrcmgr, device) # Itera sobre cada p\u00e1gina do documento PDF for page in PDFPage.create_pages(doc): # Processa o conte\u00fado de cada p\u00e1gina, convertendo-o em texto e armazenando em output_string interpreter.process_page(page) caminho : caminho de localiza\u00e7\u00e3o do arquivo Dessa forma, \u00e9 retornada a vari\u00e1vel output_string, que no arquivo leitura_NF.py, ir\u00e1 ser chamada. 2.5 Fun\u00e7\u00e3o altera\u00e7\u00e3o nome de coluna Uma utilidade do algoritmo \u00e9 criar uma coluna no dataframe com o novo nome de altera\u00e7\u00e3o do arquivo, um nome padronizado com 'razao social do prestador_codigo da empresa_valor da nota'. Esta fun\u00e7\u00e3o, coluna_altera_nome , tem como objetivo criar uma nova coluna em um DataFrame, contendo nomes de arquivos padronizados. O novo nome \u00e9 formado pela combina\u00e7\u00e3o de tr\u00eas colunas espec\u00edficas do DataFrame: \"Razao Social Prestador\", \"Codigo Tomador\", e \"Valor Liquido\". No entanto, o novo nome s\u00f3 \u00e9 gerado se os valores dessas colunas atenderem a crit\u00e9rios espec\u00edficos, incluindo a verifica\u00e7\u00e3o de certos valores indesejados e limites de caracteres. Se os crit\u00e9rios s\u00e3o satisfeitos, a fun\u00e7\u00e3o retorna o novo nome; caso contr\u00e1rio, retorna o valor original da coluna \"Arquivo\". Em situa\u00e7\u00f5es excepcionais, a fun\u00e7\u00e3o pode retornar \"Excedeu_Caracter\" se o novo nome ultrapassar o limite de caracteres ou \"Nao\" em caso de exce\u00e7\u00e3o. def coluna_altera_nome(row): # Obt\u00e9m os valores das colunas relevantes do DataFrame prestador = row['Razao Social Prestador'] tomador = row['Codigo Tomador'] valor = row['Valor Liquido'] arquivo = row['Arquivo'] try: # Verifica se os valores atendem aos crit\u00e9rios para a cria\u00e7\u00e3o de um novo nome if (prestador is not None and prestador.strip()) and prestador not in ['erro'] and prestador != 'nao_achado' and \\ tomador != '-' and \\ (valor is not None and valor.strip()) and valor not in ['erro'] and valor != 'nao_achado' and valor != '_': # Cria um novo nome conforme o padr\u00e3o estabelecido novo_nome = prestador + '__EMP' + tomador + '__' + str(valor) + '.pdf' # Verifica se o novo nome n\u00e3o excede o limite de 256 caracteres if len(novo_nome) <= 256: return novo_nome else: # Retorna um indicativo caso o novo nome exceda o limite de caracteres return 'Excedeu_Caracter' else: # Se os crit\u00e9rios n\u00e3o forem atendidos, retorna o valor original da coluna 'Arquivo' return arquivo except: # Retorna 'Nao' em caso de exce\u00e7\u00e3o return 'Nao' row : linha do DataFrame 2.6 Fun\u00e7\u00e3o limpa acento Esta fun\u00e7\u00e3o, limpa_acento , tem como objetivo remover caracteres epeciais e acentos. def limpa_acento(texto): try: return unidecode(str(texto)) except: return texto texto : entrada do texto que se deseja limpar 3.0 Arquivo \"modulos_prefeituras.py\" O prop\u00f3sito deste arquivo \u00e9 criar um script dedicado para cada prefeitura, com o objetivo de extrair informa\u00e7\u00f5es cruciais de notas fiscais. As vari\u00e1veis de interesse incluem o n\u00famero da nota, a data de emiss\u00e3o, o valor bruto, a raz\u00e3o social, o CNPJ dos prestadores e tomadores de servi\u00e7o, al\u00e9m do nome da prefeitura (local de presta\u00e7\u00e3o do servi\u00e7o). Cada script espec\u00edfico para uma prefeitura \u00e9 definido como uma fun\u00e7\u00e3o, onde um loop for \u00e9 empregado para percorrer todas as linhas do texto da nota. Dentro desse loop, h\u00e1 a busca por palavras-chave espec\u00edficas. Ao encontrar uma correspond\u00eancia, o script captura o valor associado e armazena-o em uma vari\u00e1vel. Isso permite a extra\u00e7\u00e3o eficiente de cada vari\u00e1vel relevante do texto da nota fiscal. Em alguns casos, ao inv\u00e9s de buscar por uma palavra-chave espec\u00edfica como \"data de emiss\u00e3o\", o script adota a abordagem de percorrer todo o texto em busca de padr\u00f5es, como \"dd/mm/aaaa\". Essa estrat\u00e9gia \u00e9 aplicada de maneira semelhante para a identifica\u00e7\u00e3o de CNPJ. \u00c9 importante ressaltar que tanto notas no formato de imagem quanto em PDF possuem fun\u00e7\u00f5es espec\u00edficas para cada prefeitura, e estas fornecem a vari\u00e1vel que armazena o texto da nota como entrada para a fun\u00e7\u00e3o. As vari\u00e1veis extra\u00eddas, contendo as informa\u00e7\u00f5es relevantes, s\u00e3o consolidadas em uma lista. Essa lista \u00e9 criada no m\u00f3dulo_variaveis, conforme detalhado no t\u00f3pico 2.0, e posteriormente \u00e9 utilizada para alimentar um dataframe. Essa abordagem possibilita a organiza\u00e7\u00e3o e estrutura\u00e7\u00e3o eficiente das informa\u00e7\u00f5es extra\u00eddas das notas fiscais. def pref_goncalves(texto_imagem): global prefeitura, num_nf, data_emissao, vlr_liquido, razao_prestador, razao_tomador, cpf, cnpj_prestador, cnpj_tomador # PREFEITURA prefeitura = 'PREFEITURA MUNICIPAL DE GOLCALVEZ DIAS' # extrair NUMERO NOTA FISCAL for indice, item in enumerate(texto_imagem): if 'numero da nota' in item.lower(): num_nf = texto_imagem[indice+1] break else: num_nf = 'nao_achado' # extrair DATA EMISSAO padrao = r'\\d{2}/\\d{2}/\\d{4}' posicoes = [] for elemento in texto_imagem: match = re.search(padrao, elemento) if match: posicoes.append(match.group()) else: data_emissao = 'nao_achado' data_emissao = posicoes[0] # extrair VALOR L\u00cdQUIDO for indice, item in enumerate(texto_imagem): if 'liquido' in item.lower(): vlr_liquido = texto_imagem[indice+1] break else: vlr_liquido = 'nao_achado' if ' ' in vlr_liquido: vlr_liquido = vlr_liquido.split(' ')[-1].strip() # extrair RAZ\u00c3O posicoes = [] for indice, item in enumerate(texto_imagem): if 'social' in item.lower(): posicoes.append(indice) else: razao_prestador = 'nao_achado' razao_tomador = 'nao_achado' razao_prestador = texto_imagem[posicoes[0]+1] if ':' in razao_prestador: razao_prestador = razao_prestador.split(':')[-1].strip() razao_tomador = texto_imagem[posicoes[1]+1] if ':' in razao_tomador: razao_tomador = razao_tomador.split(':')[-1].strip() # extrair CPF posicoes = [] for indice, item in enumerate(texto_imagem): if 'cpf' in item.lower(): posicoes.append(indice) else: cnpj_prestador = 'nao_achado' cnpj_tomador = 'nao_achado' padrao = r'\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}' cnpj_prestador = texto_imagem[posicoes[0]+1] if not re.findall(padrao, cnpj_prestador): cnpj_prestador = cnpj_prestador else: cnpj_prestador = re.findall(padrao, cnpj_prestador)[0] cnpj_tomador = texto_imagem[posicoes[1]+1] if not re.findall(padrao, cnpj_tomador): cnpj_tomador = cnpj_tomador else: cnpj_tomador = re.findall(padrao, cnpj_tomador)[0] Nota Por que n\u00e3o se usa apenas uma fun\u00e7\u00e3o prefeitura para extrair as vari\u00e1veis de todas as notas? A escolha de utilizar fun\u00e7\u00f5es espec\u00edficas para cada prefeitura, em vez de uma fun\u00e7\u00e3o \u00fanica para todas as notas, se deve \u00e0 natureza \u00fanica do formato de texto extra\u00eddo de cada prefeitura espec\u00edfica. Cada prefeitura pode adotar um formato \u00fanico de nota fiscal, resultando em diferen\u00e7as nos nomes das palavras-chave relevantes e nas posi\u00e7\u00f5es dessas palavras-chave no texto. Por isso \u00e9 uma fun\u00e7\u00e3o para a prefeitura de Natal, outra para a prefeitura de Gon\u00e7alves Dias, outra para Goi\u00e2nia e assim por diante. Por exemplo, o termo que representa o \"Valor Bruto\" em uma nota da prefeitura X pode ser diferente de outra nota da prefeitura Y, podendo ser \"Valor Total\" ou \"Valor dos Servi\u00e7os\". Al\u00e9m disso, as posi\u00e7\u00f5es dessas palavras-chave e dos valores associados podem variar. Mesmo para notas emitidas pela mesma prefeitura, as varia\u00e7\u00f5es na formata\u00e7\u00e3o dos PDFs e suas dimens\u00f5es podem influenciar a qualidade do texto extra\u00eddo, resultando em diferen\u00e7as nas posi\u00e7\u00f5es das palavras-chave. Por isso, usando o exemplo da prefeitura da cidade de Olimpia, h\u00e1 duas fun\u00e7\u00f5es diferentes ensse m\u00f3dulo: pref_olimpia e pref_olimpia2. Assim, a abordagem de ter fun\u00e7\u00f5es espec\u00edficas para cada prefeitura permite lidar de maneira mais flex\u00edvel com essas varia\u00e7\u00f5es, garantindo a precis\u00e3o na extra\u00e7\u00e3o das vari\u00e1veis, mesmo em cen\u00e1rios onde os formatos das notas podem ser distintos. Um ponto extremamente positivo \u00e9 que, atualmente, foi estabelecido um padr\u00e3o para notas fiscais do tipo MEI, abrangendo cerca de 50% das notas que seguem esse formato padronizado. Nesse contexto, destaca-se a fun\u00e7\u00e3o pref_danfse, especialmente desenvolvida para esse tipo espec\u00edfico de nota. Essa fun\u00e7\u00e3o demonstra uma leitura de alta qualidade e uma extra\u00e7\u00e3o de vari\u00e1veis bastante precisa. No m\u00f3dulo_prefeituras, foram implementadas quatro fun\u00e7\u00f5es dedicadas ao processamento de notas fiscais do tipo MEI. A necessidade de quatro fun\u00e7\u00f5es distintas surge de poss\u00edveis varia\u00e7\u00f5es nas dimens\u00f5es do papel da nota durante a emiss\u00e3o, o que demanda um reconhecimento espec\u00edfico para cada cen\u00e1rio. Essa abordagem permite uma extra\u00e7\u00e3o eficiente e acurada de informa\u00e7\u00f5es, contribuindo para o sucesso na interpreta\u00e7\u00e3o e manipula\u00e7\u00e3o das notas fiscais MEI, mesmo diante de poss\u00edveis varia\u00e7\u00f5es nas suas caracter\u00edsticas f\u00edsicas. 4.0 Arquivo \"modulos_renomeia.py\" Este script foi desenvolvido com o prop\u00f3sito de renomear cada arquivo de nota fiscal de acordo com os nomes indicados na coluna 'Arquivo_Nome_Alterado', mencionada no t\u00f3pico 1.12. A fun\u00e7\u00e3o renomeia (chamada no arquivo leitura_nf.py) emprega um loop para percorrer as linhas de um DataFrame (df) contendo informa\u00e7\u00f5es sobre arquivos. Em cada itera\u00e7\u00e3o, o c\u00f3digo obt\u00e9m o caminho e o nome do arquivo antigo, e ent\u00e3o cria um novo caminho com base no nome alterado e um apelido correspondente. O objetivo principal \u00e9 renomear os arquivos e atualizar as informa\u00e7\u00f5es associadas no DataFrame. Ao tentar efetuar a renomea\u00e7\u00e3o, o c\u00f3digo utiliza blocos try e except para lidar com exce\u00e7\u00f5es. Se a renomea\u00e7\u00e3o for bem-sucedida, as informa\u00e7\u00f5es no DataFrame s\u00e3o atualizadas. Em caso de falha, o c\u00f3digo tenta realizar uma limpeza nos nomes, utilizando a biblioteca unidecode para remover caracteres especiais e acentos. Se essa tentativa de limpeza tamb\u00e9m resultar em erro, o c\u00f3digo mant\u00e9m as informa\u00e7\u00f5es originais no DataFrame. Essa estrat\u00e9gia abrangente permite que o c\u00f3digo prossiga mesmo diante de poss\u00edveis problemas durante o processo de renomea\u00e7\u00e3o, garantindo robustez na execu\u00e7\u00e3o do script. import os from unidecode import unidecode def renomeia(df): # Itera sobre as linhas do DataFrame for index, linha in df.iterrows(): print('\\n') # Obt\u00e9m o caminho antigo e o nome do arquivo antigo antigo_caminho = linha['Caminho'] antigo_caminho = antigo_caminho.replace('\\\\', '/') ultima_barra = antigo_caminho.rfind('/') antigo_nome = antigo_caminho[ultima_barra:].replace('/','') # Gera o novo caminho com base no nome alterado novo_caminho = antigo_caminho ultima_barra = novo_caminho.rfind('/') novo_caminho = novo_caminho[:ultima_barra] novo_caminho = novo_caminho + '/' + linha['Arquivo_Nome_Alterado'] # Gera um apelido para o novo caminho novo_apelido = novo_caminho[ultima_barra:].replace('/','') try: # Tenta renomear o arquivo e atualizar informa\u00e7\u00f5es no DataFrame os.rename(antigo_caminho, novo_caminho) df.at[index, 'Novo_Caminho'] = str(novo_caminho).replace('/', '\\\\') df.at[index, 'Arquivo_Nome_Alterado'] = novo_apelido except Exception as e: try: # Se ocorrer uma exce\u00e7\u00e3o, tenta limpar o nome antigo usando unidecode antigo_nome_limpo = unidecode(antigo_nome) antigo_caminho_limpo = unidecode(antigo_caminho) # Atualiza informa\u00e7\u00f5es no DataFrame df.at[index, 'Arquivo_Nome_Alterado'] = antigo_nome_limpo df.at[index, 'Novo_Caminho'] = str(antigo_caminho_limpo).replace('/', '\\\\') os.rename(antigo_caminho, antigo_caminho_limpo) except: # Se a limpeza tamb\u00e9m falhar, mant\u00e9m as informa\u00e7\u00f5es originais no DataFrame df.at[index, 'Novo_Caminho'] = linha['Caminho'] df.at[index, 'Arquivo_Nome_Alterado'] = antigo_nome pass pass print('Notas renomeadas com sucesso!') df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo 5.0 Arquivo \"modulos_empresas.py\" Este script foi criado com o intuito de estabelecer uma conex\u00e3o com o banco de dados, realizar a extra\u00e7\u00e3o da tabela \"empresas\" do data warehouse (dw) e disponibilizar esses dados para serem utilizados no script de leitura de notas fiscais (t\u00f3pico 1.11 - Valida\u00e7\u00e3o do CNPJ). from sqlalchemy import create_engine import pandas as pd import psycopg2 import sqlalchemy usuario = 'usuario' senha = 'senha' host = 'host' porta = '123' banco = 'dw' engine = create_engine(f'postgresql://{usuario}:{senha}@{host}:{porta}/{banco}') try: with engine.connect() as conn: print(\"Conex\u00e3o com o banco de dados estabelecida com sucesso.\") # Seu c\u00f3digo para manipular o banco de dados query = \"select cod_empresa, empresa , cnpj from corporativo.empresas e \" global df_empresas df_empresas = pd.read_sql_query(query, engine) print('Dados carregados com sucesso') except Exception as e: print(\"Erro detectado\", e) finally: # Fechar a conex\u00e3o com o banco de dados (se ainda estiver aberta) if conn: conn.close() print('Conex\u00e3o fechada.') print(df_empresas) print(len(df_empresas)) 6.0 Arquivo \"modulos_ler_imagem.py\"","title":"Nota Fiscal"},{"location":"Leitura_Notas_Fiscais/#nota-facil","text":"","title":"Nota F\u00e1cil"},{"location":"Leitura_Notas_Fiscais/#o-que-e","text":"Trata-se de um algoritmo desenvolvido em Python, meticulosamente estruturado para processar arquivos de notas fiscais em formato PDF. O seu prop\u00f3sito \u00e9 extrair as informa\u00e7\u00f5es cruciais desses documentos, tais como n\u00famero da nota, valor l\u00edquido, data de emiss\u00e3o, CNPJ e Raz\u00e3o Social tanto do prestador quanto do tomador de servi\u00e7o. O resultado desse processo \u00e9 ent\u00e3o exportado e organizado em uma planilha do Excel, proporcionando um compilado abrangente e organizado das notas fiscais processadas.","title":"O que \u00e9?"},{"location":"Leitura_Notas_Fiscais/#ambiente","text":"Para garantir o funcionamento adequado do algoritmo, \u00e9 recomend\u00e1vel utilizar o Python fornecido pelo Anaconda. Al\u00e9m disso, \u00e9 necess\u00e1rio configurar a instala\u00e7\u00e3o de dois pacotes essenciais: Tesseract e Poopler para a leitura de imagens, conforme explicado detalhadamente no t\u00f3pico 2.0. Essa configura\u00e7\u00e3o \u00e9 crucial para garantir a efici\u00eancia e precis\u00e3o do algoritmo, permitindo uma leitura eficaz das notas fiscais em formato PDF.","title":"Ambiente"},{"location":"Leitura_Notas_Fiscais/#estrutra-do-algortimo","text":"O algoritmo \u00e9 composto por 6 arquivos em Python, de forma modularizada: leitura_NF.py modulos_vairaveis.py modulos_prefeituras.py modulos_renomeia.py modulos_empresas.py modulos_ler_imagem.py","title":"Estrutra do algortimo"},{"location":"Leitura_Notas_Fiscais/#10-arquivo-leitura_nfpy","text":"Esse \u00e9 o algoritmo que ser\u00e1 executado para o processo de leitura rodar. Primeiramente, preparo ambiente para a exporta\u00e7\u00e3o dos dados das notas. Assim, crio um DataFrame para alocar todas as vari\u00e1veis escolhidas das notas, e algumas colunas de metadados. df = pd.DataFrame(columns=['Numero NF', 'Data Emissao', 'Valor Bruto', 'CNPJ Prestador', 'CNPJ Tomador', 'Razao Social Prestador','Razao Social Tomador', 'Prefeitura', 'Script','Caminho', 'Caminho Curto', 'Arquivo']) Numero NF : n\u00famero da nota fiscal Data Emissao : data (ou data e hora) em que a nota foi emitida Valor Bruto : valor bruto da nota fiscal (sem descontos) CNPJ Prestador : n\u00famero do CNPJ do colaborador CNPJ Tomadorr : n\u00famero do CNPJ da empresa GAV Razao Social Prestador : raz\u00e3o social do colaborador Razao Social Tomador : raz\u00e3o social da empresa GAV Prefeitura : local de presta\u00e7\u00e3o do servi\u00e7o (ou prefeitura da nota emitida) Script : nome da fun\u00e7\u00e3o no c\u00f3digo que a nota foi executada Caminho : caminho original de onde vem a nota Caminho Curto : \u00faltimas 3 pastas do caminho original Arquivo : nome do arquivo","title":"1.0 Arquivo \"leitura_NF.py\""},{"location":"Leitura_Notas_Fiscais/#11-entrada-e-saida-de-dados","text":"H\u00e1 duas forma de definir o input e output dos arquivos nesse c\u00f3digo: Em formato de vari\u00e1vel, importando as vari\u00e1veis de caminho de entrada e sa\u00edda de um arquivo .env. Assim, tamb\u00e9m crio uma lista com os diret\u00f3rios de input. d1 = os.getenv('CAMINHO_NF') d2 = os.getenv('CAMINHO_NF_TLK') tabela_resposta = os.getenv('CAMINHO_RESULTADO') lista_diretorios = [d1,d2] os.getenv : recupera a vari\u00e1vel do arquivo env tabela_resposta : cont\u00e9m o caminho de exporta\u00e7\u00e3o do dataframe produzido no c\u00f3digo lista_diretorios : lista que guarda os caminhos das notas Definindo no pr\u00f3prio c\u00f3digo diretamente d1 = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Notas-Salas' d2 = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Notas-Promo-Tlmk' tabela_resposta = r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Notas_Comissoes\\Resultado\\Leitura.xlsx' lista_diretorios = [d1,d2] A diferen\u00e7a \u00e9 que a primeira torna o c\u00f3digo mais limpo e organizado.","title":"1.1 Entrada e sa\u00edda de dados"},{"location":"Leitura_Notas_Fiscais/#12-contagem-de-arquivos","text":"Ap\u00f3s estabelecer os diret\u00f3rios, navego por cada pasta e contabilizo a quantidade total de arquivos presentes. Isso \u00e9 feito com o prop\u00f3sito de criar um monitoramento que apresenta a porcentagem de notas lidas em rela\u00e7\u00e3o ao total previamente definido. Esse acompanhamento visa proporcionar uma vis\u00e3o clara do progresso na leitura das notas em rela\u00e7\u00e3o \u00e0 meta estabelecida. qtd_arquivos = 0 for i in lista_diretorios: for diretorio_atual, subdiretorios, arquivos in os.walk(lista_diretorios[lista_diretorios.index(i)]): for arquivo in arquivos: qtd_arquivos += 1","title":"1.2 Contagem de arquivos"},{"location":"Leitura_Notas_Fiscais/#13-criacao-do-loop","text":"Estabele\u00e7o um loop que percorre cada diret\u00f3rio da lista de diret\u00f3rios, adentrando em cada pasta de cada diret\u00f3rio e examinando, posteriormente, cada arquivo contido em cada pasta. Durante esse processo, verifica-se se o arquivo possui a extens\u00e3o .pdf. Caso positivo, s\u00e3o definidas duas vari\u00e1veis essenciais: o caminho completo do arquivo (caminho) e o caminho relativo em rela\u00e7\u00e3o ao diret\u00f3rio principal (caminho curto). Por fim, o script imprime o caminho completo do arquivo em quest\u00e3o. posicao = 0 for item in lista_diretorios: diretorio_inicial = lista_diretorios[posicao] posicao += 1 for diretorio_atual, subdiretorios, arquivos in os.walk(diretorio_inicial): for arquivo in arquivos: try: if arquivo.lower().endswith('.pdf'): # Se \u00e9 da extens\u00e3o .pdf caminho = diretorio_atual + '\\\\' + arquivo caminho_curto = caminho.split('\\\\')[-4:-1] caminho_curto = (caminho_curto[0] + '/' + caminho_curto[1] + '/' + caminho_curto[2]) print('CAMINHO DA NOTA =', caminho) caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho","title":"1.3 Cria\u00e7\u00e3o do Loop"},{"location":"Leitura_Notas_Fiscais/#14-leitura-da-nota","text":"Ap\u00f3s essa etapa, invoco a fun\u00e7\u00e3o respons\u00e1vel pela leitura da nota \"le_contrato\" (esclarecida no t\u00f3pico 3.0), armazenando o resultado na vari\u00e1vel \"texto\". Em seguida, o conte\u00fado passa por um processo de limpeza de espa\u00e7amentos e \u00e9 armazenado na vari\u00e1vel \"texto_lista\". Posteriormente, s\u00e3o removidos os valores vazios, transformando a vari\u00e1vel em \"texto_limpo\". Dessa forma, temos agora a vari\u00e1vel fundamental para todo o c\u00f3digo, que cont\u00e9m o texto totalmente tratado e pronto para ser utilizado nas pr\u00f3ximas etapas. # Executa fun\u00e7\u00e3o de ler o pdf modulos_variaveis_v13.le_contrato(caminho) # Armazena o texto texto = modulos_variaveis_v13.output_string.getvalue() # Tira os espa\u00e7amentos texto_lista = texto.split('\\n') caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho","title":"1.4 Leitura da Nota"},{"location":"Leitura_Notas_Fiscais/#15-direcionamento-de-prefeitura","text":"Ap\u00f3s a extra\u00e7\u00e3o do texto da nota, a vari\u00e1vel \"texto_limpo\" \u00e9 submetida a v\u00e1rias condicionais com o objetivo de determinar a qual prefeitura ela se relaciona. Uma vez identificada a prefeitura espec\u00edfica, o script executa o processo de captura das vari\u00e1veis pertinentes utilizando o \"modulo_variaveis\", cujo funcionamento ser\u00e1 detalhado posteriormente. Esse conjunto de condicionais visa direcionar o fluxo do programa para a execu\u00e7\u00e3o das etapas espec\u00edficas associadas a cada prefeitura, garantindo uma abordagem personalizada e eficiente para cada caso. # PREFEITURA DE NATAL elif any('Prefeitura Municipal do Natal' in item for item in texto_limpo): modulos_variaveis.script_natal(texto_limpo, caminho, caminho_curto, arquivo, df) # PREFEITURA DE MANAUS elif any('PREFEITURA DE MANAUS' in item for item in texto_limpo): modulos_variaveis.script_manaus(texto_limpo, caminho, caminho_curto, arquivo, df) # PREFEITURA DE RIO BRANCO elif any('Prefeitura do Munic\u00edpio de Rio Branco' in item for item in texto_limpo): modulos_variaveis.script_rio_branco(texto_limpo, caminho, caminho_curto, arquivo, df) modulos_variaveis : m\u00f3dulo que cont\u00e9m o direcionamento de cada prefeitura espec\u00edfica modulos_variaveis.script_natal : fun\u00e7\u00e3o que direciona a execu\u00e7\u00e3o da fun\u00e7\u00e3o espec\u00edfica da prefeitura natal, contida no \"modulo_variaveis\"","title":"1.5 Direcionamento de prefeitura"},{"location":"Leitura_Notas_Fiscais/#16-pdf-com-imagem","text":"Ap\u00f3s passar por todas as condicionais de processamento dos textos relacionadas \u00e0s prefeituras, o c\u00f3digo realiza uma verifica\u00e7\u00e3o final. Ele avalia se a vari\u00e1vel \"texto_limpo\" cont\u00e9m os caracteres '\\x0c' ou '\\n0'. Se essa condi\u00e7\u00e3o for satisfeita, indica que o texto \u00e9 proveniente de uma nota em PDF n\u00e3o selecion\u00e1vel, como uma imagem de um print. elif texto == '\\x0c' \\ or '\\x0c' in texto \\ or '\\n0' in texto : Nesse cen\u00e1rio, ao atender a essa condi\u00e7\u00e3o, o c\u00f3digo executa um processo para extrair os dados dessa imagem (explicado no t\u00f3pico \"modulo_ler_imagem\"), e aloca o resultado na vari\u00e1vel \"texto_imagem\". Assim, \"texto imagem\" que recebeu uma lista com o resultado da leitura da nota em imagem, passa por um processo de limpeza, eliminando caracteres vazios e linhas nulas. script = 'imagem' # Executa scritp de leitra de imagem texto_imagem = modulos_ler_imagem.get_text_from_any_pdf(caminho) texto_imagem = texto_imagem.split('\\n') texto_imagem = [item.strip() for item in texto_imagem if item.strip() != ''] caminho : caminho de localiza\u00e7\u00e3o do arquivo A partir deste ponto, o c\u00f3digo continua a percorrer as condi\u00e7\u00f5es subsequentes, verificando se o conte\u00fado se encaixa em alguma prefeitura espec\u00edfica. # PREFEITURA DE UBERABA IMAGEM elif any('PREFEITURA MUNICIPAL DE UBERABA' in item for item in texto_imagem): modulos_variaveis.script_uberaba_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) # PREFEITURA DE BEL\u00c9M IMAGEM elif any('PREFEITURA MUNICIPAL DE BELEM' in item for item in texto_imagem): modulos_variaveis.script_belem_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) # PREFEITURA DE ANANINDEUA IMAGEM elif any('PREFEITURA MUNICIPAL DE ANANINDEUA' in item for item in texto_imagem): modulos_variaveis.script_ananindeua_imagem(texto_imagem, caminho, caminho_curto, arquivo, df) modulos_variaveis : m\u00f3dulo que cont\u00e9m o direcionamento de cada prefeitura espec\u00edfica modulos_variaveis.script_uberaba_imagem : fun\u00e7\u00e3o que direciona a execu\u00e7\u00e3o da fun\u00e7\u00e3o espec\u00edfica da prefeitura de uberaba (em formato de imagem), contida no \"modulo_variaveis\" Nota Por que algumas notas s\u00e3o em formato de PDF normal e outras em formato PDF com imagem? A varia\u00e7\u00e3o no formato das notas em PDF ocorre devido ao processo descentralizado de gera\u00e7\u00e3o, onde cada colaborador \u00e9 respons\u00e1vel pela emiss\u00e3o de suas pr\u00f3prias notas. Durante esse processo, algumas notas s\u00e3o geradas de maneira n\u00e3o padr\u00e3o, resultando em PDFs com texto n\u00e3o selecion\u00e1vel.","title":"1.6 PDF com imagem"},{"location":"Leitura_Notas_Fiscais/#17-prefeitura-nao-existente","text":"Ap\u00f3s percorrer todas as condi\u00e7\u00f5es relacionadas aos casos de texto e imagem, e n\u00e3o encontrar uma correspond\u00eancia em nenhuma delas, a vari\u00e1vel \u00e9 redirecionada para a cl\u00e1usula \"else\". Nesse ponto, o c\u00f3digo tenta, pelo menos, extrair o nome da prefeitura associada ao novo caso.Se bem-sucedido, o nome da prefeitura \u00e9 extra\u00eddo, e as outras vari\u00e1veis s\u00e3o configuradas como brancas. Em seguida, todas as vari\u00e1veis s\u00e3o adicionadas a uma lista, que \u00e9 inserida no dataframe. No caso de n\u00e3o ser poss\u00edvel extrair o nome da prefeitura, a vari\u00e1vel fica com o valor \"nao_achado\", e, juntamente com as outras vari\u00e1veis em branco, uma lista \u00e9 criada e inserida como uma nova linha no dataframe. Nesse caso, a vari\u00e1vel script, que cont\u00e9m qual script da vari\u00e1vel modulo_variaveis foi ativado, fica com o valor \"sem_codigo\". Essa abordagem permite lidar de maneira flex\u00edvel com situa\u00e7\u00f5es n\u00e3o previamente mapeadas, buscando ao menos identificar o nome da prefeitura mesmo quando a estrutura do documento n\u00e3o segue os padr\u00f5es conhecidos. else: for indice, item in enumerate(texto_imagem): if 'prefeitura' in item.lower() or 'munic\u00edpio' in item.lower(): prefeitura = texto_imagem[indice] break else: prefeitura = 'nao_achado' num_nf = '' data_emissao = '' vlr_liquido = '' cnpj_prestador = '' cnpj_tomador = '' razao_prestador = '' razao_tomador = '' script = 'sem_codigo' lista_variaveis = [num_nf,data_emissao, vlr_liquido, cnpj_prestador, cnpj_tomador, razao_prestador, razao_tomador, prefeitura, script, caminho, caminho_curto, arquivo] # Inser\u00e7\u00e3o da lista no DataFrame df.loc[len(df)] = lista_variaveis df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo","title":"1.7 Prefeitura n\u00e3o existente"},{"location":"Leitura_Notas_Fiscais/#18-tentativa-e-erro","text":"Todo esse c\u00f3digo que exerce sobre esse arquivo selecionado no loop de pastas, passa por um processo de tentativa e erro, utilizando o \"try except\". Dessa forma, mesmo que ocorra algum erro durante a execu\u00e7\u00e3o, o algoritmo n\u00e3o ir\u00e1 travar. Nesse sentido, ele simplesmente ir\u00e1 entender aquela nota como erro, preencher a lista_variaveis com a palavra \"erro\" nas vari\u00e1veis, e inseri-la nno dataframe. try: if arquivo.lower().endswith('.pdf'): # Se \u00e9 da extens\u00e3o .pdf caminho = diretorio_atual + '\\\\' + arquivo caminho_curto = caminho.split('\\\\')[-4:-1] caminho_curto = (caminho_curto[0] + '/' + caminho_curto[1] + '/' + caminho_curto[2]) print('CAMINHO DA NOTA =', caminho) ... except Exception as e: lista_variaveis = ['erro', 'erro', 'erro', 'erro', 'erro', 'erro', 'erro', 'erro', e, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis","title":"1.8 Tentativa e Erro"},{"location":"Leitura_Notas_Fiscais/#19-carregamento-de-leitura","text":"Para haver um acompanhamento da leitura, o algortimo expoe no terminal algumas informa\u00e7\u00f5es: O nome do arquivo (escrito no no in\u00edcio do loop); Quantidade de notas lidas; Quantidade e porcentagem de notas imperfeitas (qualquer uma que n\u00e3o tiver a palavra \"script\" dentro da vari\u00e1vel \"script\", ou seja, que n\u00e3o tem nenhuma un\u00e7\u00e3o apropriada para aquela prefeitura); Visualiza\u00e7\u00e3o de uma barra de progresso (baseada na quantidade de notas lidas pelo total). # Calcula notas com algum tipo de erro ou n\u00e3o leitura Soma_Notas_Erro = np.sum(np.logical_not(df['Script'].str.contains('script'))) Porcentagem = round((Soma_Notas_Erro / qtd_arquivos) * 100,2) # Mostra barra de processamento print('Quantidade NOTAS LIDAS =', len(df),'/', qtd_arquivos) print('Quantidade NOTAS IMPERFEITAS =', Soma_Notas_Erro, '==', Porcentagem, '%') lista_df = list(range(1,len(df)+1)) for i in tqdm(list(range(1,len(df)+1)), total=qtd_arquivos, unit=\"item\", bar_format=\"{desc}: {percentage:.2f}% {bar}\",desc=\"Processando\"): pass qtd_arquivos : quantidade total de arquivos, calculada na sess\u00e3o \"1.2 Contagem de arquivos\"","title":"1.9 Carregamento de leitura"},{"location":"Leitura_Notas_Fiscais/#110-tratamento-e-limpeza-do-dataframe","text":"Ap\u00f3s a cria\u00e7\u00e3o do DataFrame, realiza-se ajustes para aprimorar a qualidade dos dados. Especificamente: Coluna CNPJ: Remo\u00e7\u00e3o de caracteres n\u00e3o num\u00e9ricos, mantendo apenas os d\u00edgitos. Corre\u00e7\u00e3o de um CNPJ espec\u00edfico para evitar interpreta\u00e7\u00e3o incorreta Coluna Valor: Elimina\u00e7\u00e3o de caracteres n\u00e3o num\u00e9ricos, garantindo apenas valores num\u00e9ricos. Coluna Data: Substitui\u00e7\u00e3o de '-' por '/', uniformizando o formato. Padroniza\u00e7\u00e3o de todas as datas para o formato dd/mm/aaaa. df['CNPJ Prestador'] = df['CNPJ Prestador'].str.replace(r'\\D', '', regex=True) df['CNPJ Prestador'] = df['CNPJ Prestador'].str.strip() df['CNPJ Tomador'] = df['CNPJ Tomador'].str.replace(r'\\D', '', regex=True) df['CNPJ Tomador'] = df['CNPJ Tomador'].str.strip() # Substitui a leitura errada do cnpj de GAV GRAMADO TRES df['CNPJ Tomador'] = df['CNPJ Tomador'].str.replace('90094155000102', '50094155000102') df['Valor Liquido'] = df['Valor Liquido'].str.replace(r'[a-zA-Z$]', '', regex=True) df['Data Emissao'] = df['Data Emissao'].str.replace(r'-', '/', regex=True) df['Data Emissao'] = df['Data Emissao'].str.extract(r'(\\d{2}/\\d{2}/\\d{4})', expand = False)","title":"1.10 Tratamento e Limpeza do DataFrame"},{"location":"Leitura_Notas_Fiscais/#111-validacao-do-cnpj","text":"Para validar a consist\u00eancia dos CNPJs do Tomador nas notas fiscais em rela\u00e7\u00e3o \u00e0s empresas registradas no banco de dados, realizamos a extra\u00e7\u00e3o da tabela de empresas do DW, situada no m\u00f3dulo empresas. Utilizando Python, efetuamos a limpeza e tratamento necess\u00e1rios na tabela de empresas para garantir a integridade dos dados. Em seguida, comparamos os CNPJs do Tomador nas notas fiscais com os CNPJs da tabela de empresas. Quando h\u00e1 correspond\u00eancia, incorporamos ao DataFrame das notas fiscais duas novas colunas: 'Codigo Tomador' com o c\u00f3digo da empresa correspondente, e 'Empresa Tomador' com a raz\u00e3o social correspondente. Este processo tem como objetivo assegurar a conformidade dos CNPJs do Tomador com as empresas registradas, proporcionando uma an\u00e1lise consistente dos dados. # Conex\u00e3o com tabela empresas do banco df_empresas = modulos_empresas.df_empresas df_empresas = df_empresas.drop_duplicates(subset='cnpj', keep='first') df_empresas['cod_empresa'] = df_empresas['cod_empresa'].astype(int) df_empresas['cod_empresa'] = round(df_empresas['cod_empresa']) df_empresas['cod_empresa'] = df_empresas['cod_empresa'].astype(str) # Especifica o codigo da empresa df['Codigo Tomador'] = np.where( df['CNPJ Tomador'].isin(df_empresas['cnpj']), df['CNPJ Tomador'].map(df_empresas.set_index('cnpj')['cod_empresa']), '-' ) # Especifica a razao social da empresa df['Empresa Tomador'] = np.where( df['CNPJ Tomador'].isin(df_empresas['cnpj']), df['CNPJ Tomador'].map(df_empresas.set_index('cnpj')['empresa']), '-' )","title":"1.11 Valida\u00e7\u00e3o do CNPJ"},{"location":"Leitura_Notas_Fiscais/#112-coluna-de-novos-nomes","text":"Com o intuito de padronizar os nomes dos arquivos de acordo com o conte\u00fado das notas fiscais, introduzimos uma coluna com um formato padr\u00e3o: \"Raz\u00e3o social do prestador + c\u00f3digo do tomador + valor do servi\u00e7o da nota\". A cria\u00e7\u00e3o dessa coluna \u00e9 realizada invocando a fun\u00e7\u00e3o coluna_altera_nome do m\u00f3dulo vari\u00e1veis. Posteriormente, efetuamos uma limpeza na coluna, substituindo caracteres espec\u00edficos e removendo acentos utilizando a fun\u00e7\u00e3o unidecode. Essa estrat\u00e9gia visa estabelecer uma identifica\u00e7\u00e3o uniforme e descritiva para cada nota fiscal, facilitando a organiza\u00e7\u00e3o e refer\u00eancia dos arquivos # Cria a coluna com o nome do arquivo alterado df['Arquivo_Nome_Alterado'] = df.apply(modulos_variaveis.coluna_altera_nome, axis=1) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].apply(modulos_variaveis_v13.limpa_acento) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].str.replace(\"'\", '') df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].str.replace(\"@\", '') df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].astype(str) df['Arquivo_Nome_Alterado'] = df['Arquivo_Nome_Alterado'].apply(unidecode) Depois, \u00e9 chamada a fun\u00e7\u00e3o que renomeia o pr\u00f3prio arquivo, contida no modulo renomear. # Renomeia os arquivos modulos_renomear.renomeia(df)","title":"1.12 Coluna de Novos Nomes"},{"location":"Leitura_Notas_Fiscais/#113-exportacao-do-resultado","text":"Durante o tratamento do dataframe j\u00e1 feito, utiliza-se alguns comandos de exporta\u00e7\u00e3o dessa tabela para o Excel, com o intuito de garantir que, mesmo que o c\u00f3digo d\u00ea algum erro no final, seja poss\u00edvel exportar a tabela, mesmo sem tratamento df.to_excel(r'C:\\Users\\usuario.nome\\Pasta1\\Pasta2\\Resultado.xlsx', index=False) Mas no fim do c\u00f3digo, exporta-se o dataframe pelo caminho de retorno indicado no arquivo .env df.to_excel(tabela_resposta, index=False)","title":"1.13 Exporta\u00e7\u00e3o do Resultado"},{"location":"Leitura_Notas_Fiscais/#114-contagem-do-tempo","text":"Por fim, \u00e9 exposto no terminal o tempo total da leitura das notas. # Conta o tempo de execu\u00e7\u00e3o tempo_final = time.time() tempo_total = (tempo_final - tempo_inicio)/60 print('exportado para excel') print('Tempo total', tempo_total, 'minutos')","title":"1.14 Contagem do Tempo"},{"location":"Leitura_Notas_Fiscais/#20-arquivo-modulos_variaveispy","text":"O objetivo principal deste m\u00f3dulo \u00e9 orientar a execu\u00e7\u00e3o para fun\u00e7\u00f5es espec\u00edficas dentro do m\u00f3dulo_prefeitura e tamb\u00e9m armazenar algumas fun\u00e7\u00f5es de uso geral que ser\u00e3o utilizadas no m\u00f3dulo principal.","title":"2.0 Arquivo \"modulos_variaveis.py\""},{"location":"Leitura_Notas_Fiscais/#21-funcao-para-nota-pdf","text":"Um exemplo de fun\u00e7\u00e3o de direcionamento para o m\u00f3dulo_prefeitura \u00e9 o seguinte: Inicialmente, \u00e9 determinada uma vari\u00e1vel chamada \"script\" que indica o nome do script atualmente em execu\u00e7\u00e3o. Em seguida, \u00e9 invocada a fun\u00e7\u00e3o \"pref_natal\" do m\u00f3dulo_prefeitura. Esta fun\u00e7\u00e3o \u00e9 respons\u00e1vel por extrair as vari\u00e1veis necess\u00e1rias de uma nota, seguindo o contexto do script atual. As vari\u00e1veis extra\u00eddas s\u00e3o ent\u00e3o reunidas em uma lista. Posteriormente, essa lista de vari\u00e1veis \u00e9 inserida no dataframe que est\u00e1 sendo constru\u00eddo, possibilitando a organiza\u00e7\u00e3o e manipula\u00e7\u00e3o dos dados. Este procedimento fornece uma clareza sobre o fluxo de execu\u00e7\u00e3o do script, garantindo que as vari\u00e1veis relevantes sejam corretamente extra\u00eddas e incorporadas ao dataframe em constru\u00e7\u00e3o. def script_natal(texto_limpo, caminho, caminho_curto, arquivo, df): script = 'natal_script' modulo_prefeitura.pref_natal(texto_limpo) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_limpo : texto extra\u00eddo da leitura do arquivo pdf caminho : caminho de localiza\u00e7\u00e3o do arquivo caminho_curto : as tr\u00eas \u00faltimas pastas do caminho arquivo : : nome do arquivo df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo lista_variaveis : lista contendo todas as vari\u00e1veis extra\u00eddas da nota Essa fun\u00e7\u00e3o de \"script_prefeituraX\" se repete dezenas de vezes, pois \u00e9 criado a cada prefeitura existente dentro das pastas de notas.","title":"2.1 Fun\u00e7\u00e3o para nota PDF"},{"location":"Leitura_Notas_Fiscais/#22-funcao-para-nota-pdf-de-baixa-qualidade","text":"Existe uma variante adicional da fun\u00e7\u00e3o \"script\", na qual a nota inicial \u00e9 apresentada como um texto convencional. No entanto, dentro dessa fun\u00e7\u00e3o, \u00e9 realizada uma leitura de imagem da nota para otimizar a qualidade do texto extra\u00eddo. Isso se torna especialmente relevante em casos nos quais algumas prefeituras disponibilizam notas em formato PDF comum, resultando em uma extra\u00e7\u00e3o de texto de baixa qualidade. Ao empregar a leitura de imagem, busca-se aprimorar a precis\u00e3o e clareza do texto obtido. def script_rio_largo(caminho, caminho_curto, arquivo, df): script = 'rio_largo_script' texto_imagem = modulos_ler_imagem_v1.get_text_from_any_pdf(caminho) texto_imagem = texto_imagem.split('\\n') texto_imagem = [item.strip() for item in texto_imagem if item.strip() != ''] modulos_prefeitura.pref_rio_largo(texto_imagem) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_imagem : texto extra\u00eddo da leitura do arquivo pdf com imagem","title":"2.2 Fun\u00e7\u00e3o para nota PDF de baixa qualidade"},{"location":"Leitura_Notas_Fiscais/#23-funcao-para-nota-pdf-de-imagem","text":"Existe tamb\u00e9m uma tereceira variante adicional da fun\u00e7\u00e3o \"script\", usada nas notas pdf com imagem. Com isso, em vez da entrada de texto_limpo, ter\u00e1 de texto_imagem. Neste contexto, dado que a fun\u00e7\u00e3o principal do algoritmo j\u00e1 incorpora a capacidade de realizar a leitura de imagens ao identificar que um PDF \u00e9 do tipo imagem, n\u00e3o \u00e9 necess\u00e1rio explicitar a fun\u00e7\u00e3o de leitura de imagem dentro da fun\u00e7\u00e3o \"script\". Em vez disso, basta utilizar o nome da vari\u00e1vel que cont\u00e9m a imagem como entrada para garantir a efetiva leitura e processamento. def script_recife(texto_imagem, caminho, caminho_curto, arquivo, df): script = 'recife_script' modulos_prefeitura.pref_recife(texto_imagem) lista_variaveis = [modulos_prefeitura.num_nf, modulos_prefeitura.data_emissao, modulos_prefeitura.vlr_liquido, modulos_prefeitura.cnpj_prestador, modulos_prefeitura.cnpj_tomador, modulos_prefeitura.razao_prestador, modulos_prefeitura.razao_tomador, modulos_prefeitura.prefeitura, script, caminho, caminho_curto, arquivo] df.loc[len(df)] = lista_variaveis texto_imagem : texto extra\u00eddo da leitura do arquivo pdf com imagem","title":"2.3 Fun\u00e7\u00e3o para nota PDF de imagem"},{"location":"Leitura_Notas_Fiscais/#24-funcao-para-leitura-da-nota","text":"A fun\u00e7\u00e3o le_contrato tem como objetivo ler um contrato em formato PDF, utilizando a biblioteca PDFminer Ela realiza a extra\u00e7\u00e3o de texto de cada p\u00e1gina do PDF e armazena o resultado em uma vari\u00e1vel global chamada output_string. Essa fun\u00e7\u00e3o \u00e9 \u00fatil quando se deseja processar o conte\u00fado textual de contratos presentes em documentos PDF. def le_contrato(caminho): '''L\u00ea contrato em pdf''' # Vari\u00e1vel global para armazenar o texto extra\u00eddo global output_string output_string = StringIO() # Abre o arquivo PDF no modo de leitura bin\u00e1ria with open(caminho, 'rb') as in_file: # Cria um objeto PDFParser para analisar o conte\u00fado do arquivo PDF parser = PDFParser(in_file) # Gera um objeto PDFDocument com base no parser doc = PDFDocument(parser) # Cria\u00e7\u00e3o de objetos para gerenciar recursos e converter texto rsrcmgr = PDFResourceManager() # TextConverter converte o conte\u00fado do PDF em texto device = TextConverter(rsrcmgr, output_string, laparams=LAParams()) # Cria um objeto PDFPageInterpreter para interpretar as p\u00e1ginas do PDF interpreter = PDFPageInterpreter(rsrcmgr, device) # Itera sobre cada p\u00e1gina do documento PDF for page in PDFPage.create_pages(doc): # Processa o conte\u00fado de cada p\u00e1gina, convertendo-o em texto e armazenando em output_string interpreter.process_page(page) caminho : caminho de localiza\u00e7\u00e3o do arquivo Dessa forma, \u00e9 retornada a vari\u00e1vel output_string, que no arquivo leitura_NF.py, ir\u00e1 ser chamada.","title":"2.4 Fun\u00e7\u00e3o para leitura da nota"},{"location":"Leitura_Notas_Fiscais/#25-funcao-alteracao-nome-de-coluna","text":"Uma utilidade do algoritmo \u00e9 criar uma coluna no dataframe com o novo nome de altera\u00e7\u00e3o do arquivo, um nome padronizado com 'razao social do prestador_codigo da empresa_valor da nota'. Esta fun\u00e7\u00e3o, coluna_altera_nome , tem como objetivo criar uma nova coluna em um DataFrame, contendo nomes de arquivos padronizados. O novo nome \u00e9 formado pela combina\u00e7\u00e3o de tr\u00eas colunas espec\u00edficas do DataFrame: \"Razao Social Prestador\", \"Codigo Tomador\", e \"Valor Liquido\". No entanto, o novo nome s\u00f3 \u00e9 gerado se os valores dessas colunas atenderem a crit\u00e9rios espec\u00edficos, incluindo a verifica\u00e7\u00e3o de certos valores indesejados e limites de caracteres. Se os crit\u00e9rios s\u00e3o satisfeitos, a fun\u00e7\u00e3o retorna o novo nome; caso contr\u00e1rio, retorna o valor original da coluna \"Arquivo\". Em situa\u00e7\u00f5es excepcionais, a fun\u00e7\u00e3o pode retornar \"Excedeu_Caracter\" se o novo nome ultrapassar o limite de caracteres ou \"Nao\" em caso de exce\u00e7\u00e3o. def coluna_altera_nome(row): # Obt\u00e9m os valores das colunas relevantes do DataFrame prestador = row['Razao Social Prestador'] tomador = row['Codigo Tomador'] valor = row['Valor Liquido'] arquivo = row['Arquivo'] try: # Verifica se os valores atendem aos crit\u00e9rios para a cria\u00e7\u00e3o de um novo nome if (prestador is not None and prestador.strip()) and prestador not in ['erro'] and prestador != 'nao_achado' and \\ tomador != '-' and \\ (valor is not None and valor.strip()) and valor not in ['erro'] and valor != 'nao_achado' and valor != '_': # Cria um novo nome conforme o padr\u00e3o estabelecido novo_nome = prestador + '__EMP' + tomador + '__' + str(valor) + '.pdf' # Verifica se o novo nome n\u00e3o excede o limite de 256 caracteres if len(novo_nome) <= 256: return novo_nome else: # Retorna um indicativo caso o novo nome exceda o limite de caracteres return 'Excedeu_Caracter' else: # Se os crit\u00e9rios n\u00e3o forem atendidos, retorna o valor original da coluna 'Arquivo' return arquivo except: # Retorna 'Nao' em caso de exce\u00e7\u00e3o return 'Nao' row : linha do DataFrame","title":"2.5 Fun\u00e7\u00e3o altera\u00e7\u00e3o nome de coluna"},{"location":"Leitura_Notas_Fiscais/#26-funcao-limpa-acento","text":"Esta fun\u00e7\u00e3o, limpa_acento , tem como objetivo remover caracteres epeciais e acentos. def limpa_acento(texto): try: return unidecode(str(texto)) except: return texto texto : entrada do texto que se deseja limpar","title":"2.6 Fun\u00e7\u00e3o limpa acento"},{"location":"Leitura_Notas_Fiscais/#30-arquivo-modulos_prefeituraspy","text":"O prop\u00f3sito deste arquivo \u00e9 criar um script dedicado para cada prefeitura, com o objetivo de extrair informa\u00e7\u00f5es cruciais de notas fiscais. As vari\u00e1veis de interesse incluem o n\u00famero da nota, a data de emiss\u00e3o, o valor bruto, a raz\u00e3o social, o CNPJ dos prestadores e tomadores de servi\u00e7o, al\u00e9m do nome da prefeitura (local de presta\u00e7\u00e3o do servi\u00e7o). Cada script espec\u00edfico para uma prefeitura \u00e9 definido como uma fun\u00e7\u00e3o, onde um loop for \u00e9 empregado para percorrer todas as linhas do texto da nota. Dentro desse loop, h\u00e1 a busca por palavras-chave espec\u00edficas. Ao encontrar uma correspond\u00eancia, o script captura o valor associado e armazena-o em uma vari\u00e1vel. Isso permite a extra\u00e7\u00e3o eficiente de cada vari\u00e1vel relevante do texto da nota fiscal. Em alguns casos, ao inv\u00e9s de buscar por uma palavra-chave espec\u00edfica como \"data de emiss\u00e3o\", o script adota a abordagem de percorrer todo o texto em busca de padr\u00f5es, como \"dd/mm/aaaa\". Essa estrat\u00e9gia \u00e9 aplicada de maneira semelhante para a identifica\u00e7\u00e3o de CNPJ. \u00c9 importante ressaltar que tanto notas no formato de imagem quanto em PDF possuem fun\u00e7\u00f5es espec\u00edficas para cada prefeitura, e estas fornecem a vari\u00e1vel que armazena o texto da nota como entrada para a fun\u00e7\u00e3o. As vari\u00e1veis extra\u00eddas, contendo as informa\u00e7\u00f5es relevantes, s\u00e3o consolidadas em uma lista. Essa lista \u00e9 criada no m\u00f3dulo_variaveis, conforme detalhado no t\u00f3pico 2.0, e posteriormente \u00e9 utilizada para alimentar um dataframe. Essa abordagem possibilita a organiza\u00e7\u00e3o e estrutura\u00e7\u00e3o eficiente das informa\u00e7\u00f5es extra\u00eddas das notas fiscais. def pref_goncalves(texto_imagem): global prefeitura, num_nf, data_emissao, vlr_liquido, razao_prestador, razao_tomador, cpf, cnpj_prestador, cnpj_tomador # PREFEITURA prefeitura = 'PREFEITURA MUNICIPAL DE GOLCALVEZ DIAS' # extrair NUMERO NOTA FISCAL for indice, item in enumerate(texto_imagem): if 'numero da nota' in item.lower(): num_nf = texto_imagem[indice+1] break else: num_nf = 'nao_achado' # extrair DATA EMISSAO padrao = r'\\d{2}/\\d{2}/\\d{4}' posicoes = [] for elemento in texto_imagem: match = re.search(padrao, elemento) if match: posicoes.append(match.group()) else: data_emissao = 'nao_achado' data_emissao = posicoes[0] # extrair VALOR L\u00cdQUIDO for indice, item in enumerate(texto_imagem): if 'liquido' in item.lower(): vlr_liquido = texto_imagem[indice+1] break else: vlr_liquido = 'nao_achado' if ' ' in vlr_liquido: vlr_liquido = vlr_liquido.split(' ')[-1].strip() # extrair RAZ\u00c3O posicoes = [] for indice, item in enumerate(texto_imagem): if 'social' in item.lower(): posicoes.append(indice) else: razao_prestador = 'nao_achado' razao_tomador = 'nao_achado' razao_prestador = texto_imagem[posicoes[0]+1] if ':' in razao_prestador: razao_prestador = razao_prestador.split(':')[-1].strip() razao_tomador = texto_imagem[posicoes[1]+1] if ':' in razao_tomador: razao_tomador = razao_tomador.split(':')[-1].strip() # extrair CPF posicoes = [] for indice, item in enumerate(texto_imagem): if 'cpf' in item.lower(): posicoes.append(indice) else: cnpj_prestador = 'nao_achado' cnpj_tomador = 'nao_achado' padrao = r'\\d{2}\\.\\d{3}\\.\\d{3}/\\d{4}-\\d{2}' cnpj_prestador = texto_imagem[posicoes[0]+1] if not re.findall(padrao, cnpj_prestador): cnpj_prestador = cnpj_prestador else: cnpj_prestador = re.findall(padrao, cnpj_prestador)[0] cnpj_tomador = texto_imagem[posicoes[1]+1] if not re.findall(padrao, cnpj_tomador): cnpj_tomador = cnpj_tomador else: cnpj_tomador = re.findall(padrao, cnpj_tomador)[0] Nota Por que n\u00e3o se usa apenas uma fun\u00e7\u00e3o prefeitura para extrair as vari\u00e1veis de todas as notas? A escolha de utilizar fun\u00e7\u00f5es espec\u00edficas para cada prefeitura, em vez de uma fun\u00e7\u00e3o \u00fanica para todas as notas, se deve \u00e0 natureza \u00fanica do formato de texto extra\u00eddo de cada prefeitura espec\u00edfica. Cada prefeitura pode adotar um formato \u00fanico de nota fiscal, resultando em diferen\u00e7as nos nomes das palavras-chave relevantes e nas posi\u00e7\u00f5es dessas palavras-chave no texto. Por isso \u00e9 uma fun\u00e7\u00e3o para a prefeitura de Natal, outra para a prefeitura de Gon\u00e7alves Dias, outra para Goi\u00e2nia e assim por diante. Por exemplo, o termo que representa o \"Valor Bruto\" em uma nota da prefeitura X pode ser diferente de outra nota da prefeitura Y, podendo ser \"Valor Total\" ou \"Valor dos Servi\u00e7os\". Al\u00e9m disso, as posi\u00e7\u00f5es dessas palavras-chave e dos valores associados podem variar. Mesmo para notas emitidas pela mesma prefeitura, as varia\u00e7\u00f5es na formata\u00e7\u00e3o dos PDFs e suas dimens\u00f5es podem influenciar a qualidade do texto extra\u00eddo, resultando em diferen\u00e7as nas posi\u00e7\u00f5es das palavras-chave. Por isso, usando o exemplo da prefeitura da cidade de Olimpia, h\u00e1 duas fun\u00e7\u00f5es diferentes ensse m\u00f3dulo: pref_olimpia e pref_olimpia2. Assim, a abordagem de ter fun\u00e7\u00f5es espec\u00edficas para cada prefeitura permite lidar de maneira mais flex\u00edvel com essas varia\u00e7\u00f5es, garantindo a precis\u00e3o na extra\u00e7\u00e3o das vari\u00e1veis, mesmo em cen\u00e1rios onde os formatos das notas podem ser distintos. Um ponto extremamente positivo \u00e9 que, atualmente, foi estabelecido um padr\u00e3o para notas fiscais do tipo MEI, abrangendo cerca de 50% das notas que seguem esse formato padronizado. Nesse contexto, destaca-se a fun\u00e7\u00e3o pref_danfse, especialmente desenvolvida para esse tipo espec\u00edfico de nota. Essa fun\u00e7\u00e3o demonstra uma leitura de alta qualidade e uma extra\u00e7\u00e3o de vari\u00e1veis bastante precisa. No m\u00f3dulo_prefeituras, foram implementadas quatro fun\u00e7\u00f5es dedicadas ao processamento de notas fiscais do tipo MEI. A necessidade de quatro fun\u00e7\u00f5es distintas surge de poss\u00edveis varia\u00e7\u00f5es nas dimens\u00f5es do papel da nota durante a emiss\u00e3o, o que demanda um reconhecimento espec\u00edfico para cada cen\u00e1rio. Essa abordagem permite uma extra\u00e7\u00e3o eficiente e acurada de informa\u00e7\u00f5es, contribuindo para o sucesso na interpreta\u00e7\u00e3o e manipula\u00e7\u00e3o das notas fiscais MEI, mesmo diante de poss\u00edveis varia\u00e7\u00f5es nas suas caracter\u00edsticas f\u00edsicas.","title":"3.0 Arquivo \"modulos_prefeituras.py\""},{"location":"Leitura_Notas_Fiscais/#40-arquivo-modulos_renomeiapy","text":"Este script foi desenvolvido com o prop\u00f3sito de renomear cada arquivo de nota fiscal de acordo com os nomes indicados na coluna 'Arquivo_Nome_Alterado', mencionada no t\u00f3pico 1.12. A fun\u00e7\u00e3o renomeia (chamada no arquivo leitura_nf.py) emprega um loop para percorrer as linhas de um DataFrame (df) contendo informa\u00e7\u00f5es sobre arquivos. Em cada itera\u00e7\u00e3o, o c\u00f3digo obt\u00e9m o caminho e o nome do arquivo antigo, e ent\u00e3o cria um novo caminho com base no nome alterado e um apelido correspondente. O objetivo principal \u00e9 renomear os arquivos e atualizar as informa\u00e7\u00f5es associadas no DataFrame. Ao tentar efetuar a renomea\u00e7\u00e3o, o c\u00f3digo utiliza blocos try e except para lidar com exce\u00e7\u00f5es. Se a renomea\u00e7\u00e3o for bem-sucedida, as informa\u00e7\u00f5es no DataFrame s\u00e3o atualizadas. Em caso de falha, o c\u00f3digo tenta realizar uma limpeza nos nomes, utilizando a biblioteca unidecode para remover caracteres especiais e acentos. Se essa tentativa de limpeza tamb\u00e9m resultar em erro, o c\u00f3digo mant\u00e9m as informa\u00e7\u00f5es originais no DataFrame. Essa estrat\u00e9gia abrangente permite que o c\u00f3digo prossiga mesmo diante de poss\u00edveis problemas durante o processo de renomea\u00e7\u00e3o, garantindo robustez na execu\u00e7\u00e3o do script. import os from unidecode import unidecode def renomeia(df): # Itera sobre as linhas do DataFrame for index, linha in df.iterrows(): print('\\n') # Obt\u00e9m o caminho antigo e o nome do arquivo antigo antigo_caminho = linha['Caminho'] antigo_caminho = antigo_caminho.replace('\\\\', '/') ultima_barra = antigo_caminho.rfind('/') antigo_nome = antigo_caminho[ultima_barra:].replace('/','') # Gera o novo caminho com base no nome alterado novo_caminho = antigo_caminho ultima_barra = novo_caminho.rfind('/') novo_caminho = novo_caminho[:ultima_barra] novo_caminho = novo_caminho + '/' + linha['Arquivo_Nome_Alterado'] # Gera um apelido para o novo caminho novo_apelido = novo_caminho[ultima_barra:].replace('/','') try: # Tenta renomear o arquivo e atualizar informa\u00e7\u00f5es no DataFrame os.rename(antigo_caminho, novo_caminho) df.at[index, 'Novo_Caminho'] = str(novo_caminho).replace('/', '\\\\') df.at[index, 'Arquivo_Nome_Alterado'] = novo_apelido except Exception as e: try: # Se ocorrer uma exce\u00e7\u00e3o, tenta limpar o nome antigo usando unidecode antigo_nome_limpo = unidecode(antigo_nome) antigo_caminho_limpo = unidecode(antigo_caminho) # Atualiza informa\u00e7\u00f5es no DataFrame df.at[index, 'Arquivo_Nome_Alterado'] = antigo_nome_limpo df.at[index, 'Novo_Caminho'] = str(antigo_caminho_limpo).replace('/', '\\\\') os.rename(antigo_caminho, antigo_caminho_limpo) except: # Se a limpeza tamb\u00e9m falhar, mant\u00e9m as informa\u00e7\u00f5es originais no DataFrame df.at[index, 'Novo_Caminho'] = linha['Caminho'] df.at[index, 'Arquivo_Nome_Alterado'] = antigo_nome pass pass print('Notas renomeadas com sucesso!') df : datafrane que est\u00e1 sendo constru\u00eddo durante o c\u00f3digo","title":"4.0 Arquivo \"modulos_renomeia.py\""},{"location":"Leitura_Notas_Fiscais/#50-arquivo-modulos_empresaspy","text":"Este script foi criado com o intuito de estabelecer uma conex\u00e3o com o banco de dados, realizar a extra\u00e7\u00e3o da tabela \"empresas\" do data warehouse (dw) e disponibilizar esses dados para serem utilizados no script de leitura de notas fiscais (t\u00f3pico 1.11 - Valida\u00e7\u00e3o do CNPJ). from sqlalchemy import create_engine import pandas as pd import psycopg2 import sqlalchemy usuario = 'usuario' senha = 'senha' host = 'host' porta = '123' banco = 'dw' engine = create_engine(f'postgresql://{usuario}:{senha}@{host}:{porta}/{banco}') try: with engine.connect() as conn: print(\"Conex\u00e3o com o banco de dados estabelecida com sucesso.\") # Seu c\u00f3digo para manipular o banco de dados query = \"select cod_empresa, empresa , cnpj from corporativo.empresas e \" global df_empresas df_empresas = pd.read_sql_query(query, engine) print('Dados carregados com sucesso') except Exception as e: print(\"Erro detectado\", e) finally: # Fechar a conex\u00e3o com o banco de dados (se ainda estiver aberta) if conn: conn.close() print('Conex\u00e3o fechada.') print(df_empresas) print(len(df_empresas))","title":"5.0 Arquivo \"modulos_empresas.py\""},{"location":"Leitura_Notas_Fiscais/#60-arquivo-modulos_ler_imagempy","text":"","title":"6.0 Arquivo \"modulos_ler_imagem.py\""}]}